{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH13_SET10_with_notes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzVv9TIH1GMZF23Rphcjhk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qamtam/Hands-on-machine-learning/blob/main/CH13_SET10_with_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuWklWTUSW91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "c3757719-ee1d-4475-bd49-8c9032d6d94f"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tfx==0.21.2\n",
        "    print(\"You can safely ignore the package incompatibility errors.\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 2.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 16.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 26.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.2MB 67kB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 47.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 38.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 53.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 43.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9MB 48.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.4MB 41.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 50.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 49.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 49.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 51.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 36.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 49.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 51.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 55.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 48.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7MB 47.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 48.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 53.7MB/s \n",
            "\u001b[?25h  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-transform (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for httplib2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.7.12 has requirement httplib2<1dev,>=0.17.0, but you'll have httplib2 0.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-transform 0.21.2 has requirement tensorflow<2.2,>=1.15, but you'll have tensorflow 2.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-data-validation 0.21.5 has requirement pandas<1,>=0.24, but you'll have pandas 1.1.2 which is incompatible.\u001b[0m\n",
            "You can safely ignore the package incompatibility errors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXFcismXS9ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "275edf20-8630-44e2-adb3-b868974a5d1f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import data\n",
        "BytesList = tf.train.BytesList\n",
        "FloatList = tf.train.FloatList\n",
        "Int64List = tf.train.Int64List\n",
        "Feature = tf.train.Feature\n",
        "Features = tf.train.Features\n",
        "Example = tf.train.Example\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1DEanoGTpCw"
      },
      "source": [
        "def create_example(image, label):\n",
        "    im = tf.io.serialize_tensor(image)\n",
        "  #  print(im.numpy()) <-- jeden długi płaski string\n",
        "    return Example(\n",
        "        features = Features(\n",
        "            feature={\n",
        "                \"image\": Feature(bytes_list=BytesList(value=[im.numpy()])),\n",
        "                \"label\": Feature(int64_list=Int64List(value=[label]))\n",
        "            }\n",
        "        )\n",
        "    ) #not serialized yet, it is just an object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqFb-qemTtCl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3sORR0lT6ue"
      },
      "source": [
        "#try to read\n",
        "feature_description = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"), #shape płaski, bo czytamy z płaskiego stringa, reshape zrobimy później\n",
        "    \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KrqA_8LUqyx"
      },
      "source": [
        "# ta funkcja zapisze dany dataset do kilku plików typu tfrecord\n",
        "\n",
        "# contextlib exitstack jest klasą kltóra pilnuje, żeby wszystkie procesy zapisywania domknęły się poprawnie\n",
        "from contextlib import ExitStack\n",
        "def write_tfrecords(name, dataset, n_shards=10):\n",
        "  paths  = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards) for index in range(n_shards)] #name.tfrecord-00000-of-00010\n",
        "  with ExitStack() as stack:\n",
        "    writers = [stack.enter_context(tf.io.TFRecordWriter(path)) for path in paths] #entercontext to tak jakby with tf.io. ... . as f\n",
        "    for index, (image, label) in dataset.enumerate():\n",
        "      shard = index % n_shards\n",
        "      example= create_example(image, label)\n",
        "      writers[shard].write(example.SerializeToString())\n",
        "  return paths\n",
        "\n",
        "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
        "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
        "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
        "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
        "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIiam-tBVGe_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "9d34d653-f1c9-4689-809a-9fb33c450124"
      },
      "source": [
        "train_filepaths"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my_fashion_mnist.train.tfrecord-00000-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00001-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00002-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00003-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00004-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00005-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00006-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00007-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00008-of-00010',\n",
              " 'my_fashion_mnist.train.tfrecord-00009-of-00010']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufCY7tq5Wylx"
      },
      "source": [
        "# preprocesowanie tu to odczytanie zakodowanego i zserializowanego Example\n",
        "def preprocess(tfrecord):\n",
        "  feature_description = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"), #shape płaski, bo czytamy z płaskiego stringa, reshape zrobimy później\n",
        "    \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1),\n",
        "  }\n",
        "  example = tf.io.parse_example(tfrecord, feature_description) # tu już mamy dwa tensory\n",
        "  #{'image': <tf.Tensor 'ParseExample/ParseExampleV2:0' shape=() dtype=string>, 'label': <tf.Tensor 'ParseExample/ParseExampleV2:1' shape=() dtype=int64>}\n",
        "  image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8) #przerabiamy zestringowany tensor na tensor typu uint8 \n",
        "    #image = tf.io.decode_jpeg(example[\"image\"])\n",
        "  image = tf.reshape(image, shape=[28, 28])\n",
        "  return image, example[\"label\"]\n",
        "\n",
        "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
        "                  n_parse_threads=5, batch_size=32, cache=True):\n",
        "    dataset = tf.data.TFRecordDataset(filepaths,\n",
        "                                      num_parallel_reads=n_read_threads)\n",
        "    if cache: #wciśnij do ramu\n",
        "        dataset = dataset.cache()\n",
        "    if shuffle_buffer_size: # przemieszaj, jeśli jest potrzeba\n",
        "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads) #rozpakuj zapakowane example\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1)\n",
        "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
        "valid_set = mnist_dataset(train_filepaths)\n",
        "test_set = mnist_dataset(train_filepaths)\n",
        "train_set_micro = mnist_dataset(train_filepaths, batch_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_OAdSs7YkM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6416d84-07e0-48ea-f012-802e6c7f743e"
      },
      "source": [
        "sample = train_set_micro.take(1).map(lambda image, label: image) #zostaje samo zdjęcie\n",
        "for x in sample:\n",
        "  print(x.shape)\n",
        "#sample_numpy = sample.as_numpy_iterator()\n",
        "#x = sample_numpy\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "numpy.set_printoptions(linewidth=np.inf)\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(sample)\n",
        "print(normalizer.mean)\n",
        "normalizer2 = preprocessing.Normalization(axis=(1,2))\n",
        "normalizer2.adapt(sample)\n",
        "norma_mean = normalizer2.mean.numpy() # średnia w batchu po każdej komórce\n",
        "norma0_mean = normalizer.mean.numpy() # średnia w batchu po całych kolumnach\n",
        "\n",
        "print(normalizer2.mean.numpy())\n",
        "print(numpy.sum(normalizer2.mean[:,1].numpy())/28) ## przeobiona średnia z komórkowych na jedną średnią kolumnnową\n",
        "for x in sample:\n",
        "  print(x)\n",
        "  mean0 = np.mean(x, axis=0)\n",
        "  mean1 = np.mean(x, axis=1)\n",
        "  mean2 = np.mean(x, axis=2)\n",
        "  mean01 = np.mean(x, axis=(0,1)) # też średnia po kolumnach (czyli z całej kolumny 1 tabeli + całej kolumny 2 tabeli)\n",
        "  # wychodzi średnia z 28 liczb\n",
        "  mean = np.mean(x)\n",
        " #   print(mean) średnia ze wszystkiego, jedna liczbaa\n",
        "  #print(mean0)\n",
        "  print(mean0-norma_mean)\n",
        "  print(\"####\")\n",
        "  print(norma0_mean-mean01)\n",
        "  print(norma0_mean)\n",
        "  print(mean01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 28, 28)\n",
            "<tf.Variable 'mean:0' shape=(28,) dtype=float32, numpy=array([10.660714 , 17.928572 , 14.178572 , 41.607143 , 63.857143 , 56.75     , 61.357143 , 62.910713 , 63.589287 , 60.214287 , 58.232143 , 55.5      , 48.19643  , 47.482143 , 48.875    , 48.30357  , 48.232143 , 51.464287 , 51.92857  , 52.607143 , 46.339287 , 48.67857  , 48.089287 , 20.321428 , 13.625    ,  7.25     ,  4.821429 ,  2.5714285], dtype=float32)>\n",
            "[[  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.   18.5  13.5   8.    7.    8.    6.5   4.    2.5   2.5   8.    8.5   7.    6.    6.   10.   12.    5.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.   17.   45.   52.   94.   73.   91.   88.   88.5  89.   84.   81.   82.   86.   84.5  85.   88.5  85.   93.5  76.   78.5   9.    0.    0.    0.5   0.5   0.    0. ]\n",
            " [ 16.   97.    0.   54.5  80.   64.   84.   86.5  87.   89.   86.   84.5  84.   87.   85.   84.5  87.   80.5  83.   76.5  79.   87.   42.    0.    2.    0.    0.5   0. ]\n",
            " [ 57.5  25.5   0.   45.   83.   60.   90.   90.5  87.   91.   90.   88.5  89.5  86.5  86.   85.   86.   88.5  92.   72.5  80.   97.5  57.    0.   31.5   0.    0.5   0. ]\n",
            " [ 57.5   0.    0.   47.   98.5  65.   85.   86.   86.5 104.5  90.5  86.5  85.   86.   88.5  87.   90.   89.5  88.   72.5  80.5  84.5  16.   62.  128.5  45.    0.5   0.5]\n",
            " [ 44.    0.    0.   48.5  84.   64.5  85.  116.  147.  159.  105.   89.   87.   86.5  90.5  87.   86.   90.   92.   77.5  86.5  76.   69.  107.5  79.5   0.5   0.5   0. ]\n",
            " [ 30.5   0.    0.   55.  107.  106.  148.  157.5 138.5 118.5 118.   90.   86.   82.5  90.   94.5  90.5  96.   83.5  77.   92.  147.5 131.   83.5   0.5   0.5   0.    0. ]\n",
            " [ 27.   30.5  33.   87.5 170.5 138.5 108.5 111.  118.5 122.5 139.5 112.5  95.   99.   93.5  94.   86.   77.   78.   86.5 172.  200.  202.5   0.    0.    0.5   0.5   0. ]\n",
            " [ 28.5 152.   56.   78.5 137.   99.5  95.   97.5 106.  119.5 141.  126.5  79.   82.   85.   85.5  79.   84.   87.  182.5 184.  203.5 120.5   8.    0.5   2.    0.    0. ]\n",
            " [ 10.5 114.  152.5 144.  180.5 152.5 146.  147.  143.  146.5 139.5 153.5  93.5  81.   89.5  92.   87.  114.  177.5 198.  173.  112.  110.   10.    0.    0.5   0.    0. ]\n",
            " [ 22.   62.5 107.5 159.  166.5 178.  185.5 168.5 158.  145.5 134.5 143.  131.  100.5 100.  102.5 120.5 213.5 192.5 194.  103.5 114.5 124.   40.   16.   17.   18.   16. ]\n",
            " [  3.5   3.5   3.   54.5 105.  105.5 106.  114.5 112.5  94.   79.   87.5  88.   91.   94.  103.5 109.   87.   87.   87.   64.5 121.  118.5  59.   18.   20.   19.5  18.5]\n",
            " [  0.    0.    0.    8.5 106.5 111.  112.5 113.  104.5 101.5  88.   90.   85.   82.5  79.   73.5  83.5  90.   98.5  88.   64.   75.5  99.5  18.    6.    7.    6.    0. ]\n",
            " [  0.5   0.    0.  113.  102.  104.5 126.  121.5 117.5 101.5 105.   91.   67.   79.  104.   97.   90.   88.   54.5  88.   35.   35.  100.    0.    0.    0.    0.    1. ]\n",
            " [  0.5   0.    0.   83.   93.5  89.   82.5  81.5  89.5  75.  102.5 100.5  86.5  88.   94.   90.   82.5  74.5  90.5  85.    0.    0.  109.5  74.    0.    0.    0.    0. ]\n",
            " [  0.5   0.    0.  107.  100.5 102.   98.5 102.5 112.  101.  124.  127.5 108.5 104.   96.5  84.5  79.   77.5  46.5   0.    0.    0.   47.  107.   92.5  79.   68.5  36. ]\n",
            " [  0.    0.    0.   28.   61.   62.5  66.5  73.   76.5  21.5   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.   30.5  20.5   0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n",
            " [  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0. ]]\n",
            "17.928571428571427\n",
            "tf.Tensor(\n",
            "[[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0  37  27  16  14  16  13   8   5   5  16  17  14  12  12  20  24  10   0   0   0   0   0   0   0]\n",
            "  [  0  34  90 104 188 146 182 176 177 178 168 162 164 172 169 170 177 170 187 152 157  18   0   0   1   1   0   0]\n",
            "  [ 32 194   0 109 160 128 168 173 174 178 172 169 168 174 170 169 174 161 166 153 158 174  84   0   4   0   1   0]\n",
            "  [115  51   0  90 166 120 177 180 174 182 180 177 179 173 172 170 172 177 184 145 160 195 114   0   1   0   1   0]\n",
            "  [115   0   0  94 197 130 170 172 173 185 181 173 170 172 177 174 180 179 176 145 161 169  32   0   2   0   1   0]\n",
            "  [ 88   0   0  97 168 129 170 179 179 179 180 178 174 173 181 174 172 180 184 155 173 152   0   0   1   1   1   0]\n",
            "  [ 61   0   0 110 190 139 166 188 187 181 172 180 172 165 179 186 180 192 161 154 184 123  46   0   1   1   0   0]\n",
            "  [ 54  42   0  66 225 164 133 163 181 187 187 198 190 198 186 187 172 153 156 172 149 196 209   0   0   1   0   0]\n",
            "  [  1 160   0  62 196 141 160 157 150 158 161 166 158 164 166 171 158 168 173 166 166 225 238  16   0   1   0   0]\n",
            "  [  0  60 160 153 226 180 157 158 162 174 169 166 157 162 179 184 174 187 173 197 176 220 220  20   0   1   0   0]\n",
            "  [  3   0  91 202 200 227 232 204 198 181 176 165 172 186 176 193 202 189 189 198 141 229 210  48   0   2   0   0]\n",
            "  [  0   0   0 102 204 201 202 216 212 172 137 149 150 146 152 171 192 174 174 174 125 204 204  80   0   5   0   1]\n",
            "  [  0   0   0  17 213 222 225 226 209 203 176 180 170 165 158 147 166 180 187 157 107 133 192  26   0   1   0   0]\n",
            "  [  1   0   0 226 204 209 252 243 235 203 210 182 134 158 208 194 180 176 109 176  70  70 200   0   0   0   0   2]\n",
            "  [  1   0   0 166 187 178 165 163 179 150 205 201 173 176 188 180 165 149 181 170   0   0 219 148   0   0   0   0]\n",
            "  [  1   0   0 214 201 204 197 205 224 202 248 255 217 208 193 169 158 155  93   0   0   0  94 214 185 158 137  72]\n",
            "  [  0   0   0  56 122 125 133 146 153  43   0   0   0   0   0   0   0   0   0   0   0   0   0   0  12  61  41   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "\n",
            " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   3   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  62   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0  24   0   0   0   0   0   0   0   0   0   0   0   0   0 124 255  90   0   1]\n",
            "  [  0   0   0   0   0   0   0  53 115 139  30   0   0   0   0   0   0   0   0   0   0   0 138 215 158   0   0   0]\n",
            "  [  0   0   0   0  24  73 130 127  90  56  64   0   0   0   1   3   1   0   6   0   0 172 216 167   0   0   0   0]\n",
            "  [  0  19  66 109 116 113  84  59  56  58  92  27   0   0   1   1   0   1   0   1 195 204 196   0   0   0   1   0]\n",
            "  [ 56 144 112  95  78  58  30  38  62  81 121  87   0   0   4   0   0   0   1 199 202 182   3   0   1   3   0   0]\n",
            "  [ 21 168 145 135 135 125 135 136 124 119 110 141  30   0   0   0   0  41 182 199 170   4   0   0   0   0   0   0]\n",
            "  [ 41 125 124 116 133 129 139 133 118 110  93 121  90  15  24  12  39 238 196 190  66   0  38  32  32  32  36  32]\n",
            "  [  7   7   6   7   6  10  10  13  13  16  21  26  26  36  36  36  26   0   0   0   4  38  33  38  36  35  39  36]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0  10  19  21  18   7  10  12  13  12   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]], shape=(2, 28, 28), dtype=uint8)\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "####\n",
            "[-1.36239189e-07  2.72478378e-07  2.72478376e-07  5.44956755e-07  5.44956755e-07  0.00000000e+00  5.44956755e-07 -1.08991350e-06  1.08991350e-06  1.08991350e-06  5.44956755e-07  0.00000000e+00  1.63487026e-06  5.44956755e-07  0.00000000e+00 -1.63487026e-06  5.44956755e-07  1.08991350e-06 -1.63487026e-06  5.44956755e-07  1.08991350e-06 -1.63487026e-06  1.08991350e-06 -2.72478378e-07  0.00000000e+00  0.00000000e+00  2.04358782e-07 -3.40597972e-08]\n",
            "[10.660714  17.928572  14.178572  41.607143  63.857143  56.75      61.357143  62.910713  63.589287  60.214287  58.232143  55.5       48.19643   47.482143  48.875     48.30357   48.232143  51.464287  51.92857   52.607143  46.339287  48.67857   48.089287  20.321428  13.625      7.25       4.821429   2.5714285]\n",
            "[10.66071429 17.92857143 14.17857143 41.60714286 63.85714286 56.75       61.35714286 62.91071429 63.58928571 60.21428571 58.23214286 55.5        48.19642857 47.48214286 48.875      48.30357143 48.23214286 51.46428571 51.92857143 52.60714286 46.33928571 48.67857143 48.08928571 20.32142857 13.625       7.25        4.82142857  2.57142857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbAISL11j3Fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a29b46-f07d-4423-8f69-07c6b8237310"
      },
      "source": [
        "for x in tf.data.Dataset.__iter__(sample): #how to simply iterate over dataset\n",
        "  print(np.mean(x, axis=(0)).shape) # po wartościach\n",
        "  #print(np.mean(x, axis=(0,1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXQg4FpXj4Ev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3009158b-6e3a-49a8-b71d-5bbaaa4b4ba5"
      },
      "source": [
        "#try standarization\n",
        "#0 axis is the  batch axis\n",
        "#so for example in fasion mnist we do have tables (tensors) of shape 32*28*28\n",
        "#or 32 units * 784 features\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(sample)\n",
        "print(normalizer.mean)\n",
        "normalizer2 = preprocessing.Normalization(axis=(1,2))\n",
        "normalizer2.adapt(sample)\n",
        "print(normalizer2.mean)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'mean:0' shape=(28,) dtype=float32, numpy=\n",
            "array([  2.1149554,   3.794643 ,   6.9162946,  14.970983 ,  27.837053 ,\n",
            "        47.78125  ,  59.515625 ,  66.97768  ,  73.967636 ,  93.720985 ,\n",
            "       116.345985 , 120.08259  , 120.737724 , 111.03571  , 106.71429  ,\n",
            "       114.97321  , 124.54576  , 119.69196  , 115.32701  ,  91.44196  ,\n",
            "        77.36384  ,  71.69308  ,  61.27902  ,  46.71317  ,  27.46317  ,\n",
            "        16.015625 ,  11.436384 ,   4.051339 ], dtype=float32)>\n",
            "<tf.Variable 'mean:0' shape=(28, 28) dtype=float32, numpy=\n",
            "array([[0.0000000e+00, 3.1250000e-02, 0.0000000e+00, 3.1250000e-02,\n",
            "        1.2500000e-01, 1.5625000e-01, 1.0000000e+00, 2.9062500e+00,\n",
            "        5.6250000e+00, 1.9937500e+01, 3.9531250e+01, 6.4687500e+01,\n",
            "        6.4031250e+01, 5.4843750e+01, 5.3875000e+01, 6.1437500e+01,\n",
            "        6.2593750e+01, 5.5968750e+01, 2.4500000e+01, 5.2500000e+00,\n",
            "        2.2500000e+00, 1.8437500e+00, 1.8750000e-01, 1.2500000e-01,\n",
            "        3.1250000e-02, 0.0000000e+00, 3.1250000e-02, 0.0000000e+00],\n",
            "       [0.0000000e+00, 3.1250000e-02, 6.2500000e-02, 3.1250000e-02,\n",
            "        5.9375000e-01, 5.5000000e+00, 8.8437500e+00, 3.7093750e+01,\n",
            "        6.0812500e+01, 8.6406250e+01, 1.0993750e+02, 1.2503125e+02,\n",
            "        1.2656250e+02, 1.1965625e+02, 1.2818750e+02, 1.3368750e+02,\n",
            "        1.2406250e+02, 1.1540625e+02, 1.0356250e+02, 6.9406250e+01,\n",
            "        4.1031250e+01, 1.3968750e+01, 6.5625000e+00, 2.2500000e+00,\n",
            "        3.1250000e-02, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "       [0.0000000e+00, 9.3750000e-02, 0.0000000e+00, 1.5625000e-01,\n",
            "        5.2500000e+00, 1.2812500e+01, 4.3406250e+01, 6.5406250e+01,\n",
            "        7.9250000e+01, 9.8968750e+01, 1.2053125e+02, 1.2271875e+02,\n",
            "        1.2746875e+02, 1.3268750e+02, 1.4187500e+02, 1.3496875e+02,\n",
            "        1.2256250e+02, 1.1450000e+02, 1.1212500e+02, 8.9875000e+01,\n",
            "        7.4093750e+01, 5.4843750e+01, 1.7937500e+01, 7.5000000e+00,\n",
            "        1.3437500e+00, 1.1875000e+00, 3.1250000e-02, 0.0000000e+00],\n",
            "       [0.0000000e+00, 1.5625000e-01, 0.0000000e+00, 1.7187500e+00,\n",
            "        1.0718750e+01, 3.6968750e+01, 6.2562500e+01, 7.8031250e+01,\n",
            "        9.6000000e+01, 1.1093750e+02, 1.1884375e+02, 1.2053125e+02,\n",
            "        1.2546875e+02, 1.3162500e+02, 1.2868750e+02, 1.3746875e+02,\n",
            "        1.2975000e+02, 1.1931250e+02, 1.2600000e+02, 1.0906250e+02,\n",
            "        8.7968750e+01, 8.2250000e+01, 6.0500000e+01, 2.2843750e+01,\n",
            "        7.8750000e+00, 5.5312500e+00, 4.3750000e-01, 0.0000000e+00],\n",
            "       [0.0000000e+00, 3.1250000e-02, 0.0000000e+00, 3.8437500e+00,\n",
            "        2.1437500e+01, 5.3625000e+01, 8.1343750e+01, 9.5468750e+01,\n",
            "        1.0559375e+02, 1.0890625e+02, 1.1853125e+02, 1.2218750e+02,\n",
            "        1.1815625e+02, 1.2500000e+02, 1.1584375e+02, 1.2428125e+02,\n",
            "        1.2943750e+02, 1.2125000e+02, 1.2221875e+02, 1.1346875e+02,\n",
            "        1.0756250e+02, 9.3406250e+01, 8.1093750e+01, 3.0843750e+01,\n",
            "        1.0531250e+01, 4.2187500e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "       [0.0000000e+00, 3.1250000e-02, 0.0000000e+00, 5.5000000e+00,\n",
            "        3.1031250e+01, 6.5656250e+01, 8.9812500e+01, 1.0178125e+02,\n",
            "        9.9843750e+01, 9.9593750e+01, 1.1134375e+02, 1.2087500e+02,\n",
            "        1.1803125e+02, 1.2265625e+02, 1.2000000e+02, 1.3009375e+02,\n",
            "        1.2509375e+02, 1.1018750e+02, 1.1268750e+02, 1.0996875e+02,\n",
            "        1.0853125e+02, 1.1146875e+02, 8.6062500e+01, 3.8031250e+01,\n",
            "        1.4500000e+01, 4.8437500e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "       [0.0000000e+00, 4.6875000e-01, 1.4687500e+00, 1.0968750e+01,\n",
            "        3.8562500e+01, 7.5343750e+01, 9.6406250e+01, 1.0359375e+02,\n",
            "        1.0487500e+02, 1.0078125e+02, 1.1781250e+02, 1.2840625e+02,\n",
            "        1.2293750e+02, 1.1456250e+02, 1.1950000e+02, 1.2253125e+02,\n",
            "        1.2112500e+02, 1.1628125e+02, 1.1650000e+02, 1.1721875e+02,\n",
            "        1.1590625e+02, 1.1803125e+02, 9.8375000e+01, 5.3500000e+01,\n",
            "        1.5187500e+01, 6.6875000e+00, 9.3750000e-02, 2.5000000e-01],\n",
            "       [5.5312500e+00, 6.9375000e+00, 5.7187500e+00, 1.6625000e+01,\n",
            "        5.3093750e+01, 8.4593750e+01, 1.0271875e+02, 1.1065625e+02,\n",
            "        1.0350000e+02, 1.0021875e+02, 1.2096875e+02, 1.2409375e+02,\n",
            "        1.1812500e+02, 1.1331250e+02, 1.1168750e+02, 1.1915625e+02,\n",
            "        1.2612500e+02, 1.2678125e+02, 1.2625000e+02, 1.2440625e+02,\n",
            "        1.2521875e+02, 1.2606250e+02, 1.0671875e+02, 6.8875000e+01,\n",
            "        2.8968750e+01, 1.5281250e+01, 1.1375000e+01, 6.9687500e+00],\n",
            "       [6.0937500e+00, 5.1875000e+00, 4.7500000e+00, 1.5593750e+01,\n",
            "        5.5593750e+01, 8.3812500e+01, 1.0159375e+02, 1.1565625e+02,\n",
            "        9.0000000e+01, 9.4937500e+01, 1.1478125e+02, 1.2365625e+02,\n",
            "        1.2587500e+02, 1.3159375e+02, 1.2259375e+02, 1.2581250e+02,\n",
            "        1.4287500e+02, 1.5365625e+02, 1.2371875e+02, 1.1181250e+02,\n",
            "        1.2243750e+02, 1.2803125e+02, 1.0315625e+02, 7.0125000e+01,\n",
            "        3.7125000e+01, 1.8937500e+01, 1.4812500e+01, 5.4687500e+00],\n",
            "       [3.7187500e+00, 5.2500000e+00, 5.4062500e+00, 2.1000000e+01,\n",
            "        6.6250000e+01, 7.9562500e+01, 1.0193750e+02, 1.2659375e+02,\n",
            "        9.2687500e+01, 9.0968750e+01, 1.2234375e+02, 1.3234375e+02,\n",
            "        1.2915625e+02, 1.3246875e+02, 1.3059375e+02, 1.3831250e+02,\n",
            "        1.6618750e+02, 1.6262500e+02, 1.2231250e+02, 1.0628125e+02,\n",
            "        1.2637500e+02, 1.3062500e+02, 1.0437500e+02, 8.7343750e+01,\n",
            "        3.5406250e+01, 2.1656250e+01, 2.5781250e+01, 4.8125000e+00],\n",
            "       [2.1875000e-01, 5.5000000e+00, 6.8437500e+00, 2.7625000e+01,\n",
            "        7.1437500e+01, 8.2468750e+01, 1.0137500e+02, 1.1490625e+02,\n",
            "        9.5562500e+01, 8.4843750e+01, 1.1971875e+02, 1.3393750e+02,\n",
            "        1.3934375e+02, 1.4040625e+02, 1.4953125e+02, 1.6071875e+02,\n",
            "        1.5162500e+02, 1.6243750e+02, 1.3150000e+02, 1.0746875e+02,\n",
            "        1.2512500e+02, 1.3006250e+02, 1.1231250e+02, 9.6031250e+01,\n",
            "        4.1625000e+01, 2.9593750e+01, 3.1031250e+01, 9.7500000e+00],\n",
            "       [1.2500000e-01, 4.8125000e+00, 9.5937500e+00, 2.4187500e+01,\n",
            "        5.9562500e+01, 8.0593750e+01, 1.0093750e+02, 9.1250000e+01,\n",
            "        9.0093750e+01, 1.0175000e+02, 1.3268750e+02, 1.5196875e+02,\n",
            "        1.5109375e+02, 1.5684375e+02, 1.4793750e+02, 1.5075000e+02,\n",
            "        1.5325000e+02, 1.6637500e+02, 1.4734375e+02, 1.2175000e+02,\n",
            "        1.1481250e+02, 1.2303125e+02, 1.1996875e+02, 9.1281250e+01,\n",
            "        4.8468750e+01, 5.2031250e+01, 4.0250000e+01, 1.9687500e+00],\n",
            "       [5.3125000e-01, 4.6562500e+00, 1.2687500e+01, 2.6406250e+01,\n",
            "        5.7656250e+01, 8.1343750e+01, 9.8656250e+01, 8.9218750e+01,\n",
            "        1.0056250e+02, 1.1700000e+02, 1.5106250e+02, 1.6421875e+02,\n",
            "        1.5843750e+02, 1.6531250e+02, 1.5956250e+02, 1.5590625e+02,\n",
            "        1.5321875e+02, 1.5465625e+02, 1.5290625e+02, 1.2462500e+02,\n",
            "        1.2412500e+02, 1.2859375e+02, 1.1703125e+02, 1.1106250e+02,\n",
            "        6.2906250e+01, 5.6500000e+01, 3.4562500e+01, 7.8125000e-01],\n",
            "       [9.3750000e-02, 5.0312500e+00, 1.6750000e+01, 2.8093750e+01,\n",
            "        6.0437500e+01, 8.5875000e+01, 1.0306250e+02, 1.0359375e+02,\n",
            "        1.1181250e+02, 1.3781250e+02, 1.5684375e+02, 1.6109375e+02,\n",
            "        1.4768750e+02, 1.5081250e+02, 1.5446875e+02, 1.5131250e+02,\n",
            "        1.5906250e+02, 1.7009375e+02, 1.6946875e+02, 1.3237500e+02,\n",
            "        1.2337500e+02, 1.3071875e+02, 1.1206250e+02, 1.1037500e+02,\n",
            "        6.3687500e+01, 5.9781250e+01, 3.7250000e+01, 2.9687500e+00],\n",
            "       [1.5937500e+00, 1.2218750e+01, 2.5937500e+01, 4.0968750e+01,\n",
            "        7.3875000e+01, 9.1593750e+01, 1.0862500e+02, 1.0103125e+02,\n",
            "        1.0681250e+02, 1.3512500e+02, 1.6421875e+02, 1.6306250e+02,\n",
            "        1.5443750e+02, 1.5434375e+02, 1.5346875e+02, 1.5453125e+02,\n",
            "        1.5415625e+02, 1.6150000e+02, 1.6903125e+02, 1.3546875e+02,\n",
            "        1.1825000e+02, 1.3196875e+02, 1.2596875e+02, 1.1534375e+02,\n",
            "        6.8875000e+01, 6.5281250e+01, 4.6500000e+01, 1.1125000e+01],\n",
            "       [3.6562500e+00, 2.1031250e+01, 3.8468750e+01, 5.7968750e+01,\n",
            "        8.9000000e+01, 1.0606250e+02, 1.1565625e+02, 1.0656250e+02,\n",
            "        1.2243750e+02, 1.5475000e+02, 1.6978125e+02, 1.7762500e+02,\n",
            "        1.6840625e+02, 1.5856250e+02, 1.5528125e+02, 1.5937500e+02,\n",
            "        1.6450000e+02, 1.6887500e+02, 1.6912500e+02, 1.4925000e+02,\n",
            "        1.2003125e+02, 1.3812500e+02, 1.2765625e+02, 1.2812500e+02,\n",
            "        8.0312500e+01, 6.5343750e+01, 5.7250000e+01, 1.6750000e+01],\n",
            "       [6.5625000e+00, 3.5031250e+01, 4.0250000e+01, 5.2875000e+01,\n",
            "        8.7875000e+01, 1.0671875e+02, 1.1725000e+02, 1.1412500e+02,\n",
            "        1.3453125e+02, 1.5671875e+02, 1.7212500e+02, 1.7643750e+02,\n",
            "        1.7690625e+02, 1.6759375e+02, 1.6109375e+02, 1.6784375e+02,\n",
            "        1.6812500e+02, 1.7506250e+02, 1.8103125e+02, 1.8028125e+02,\n",
            "        1.2153125e+02, 1.4381250e+02, 1.3950000e+02, 1.3503125e+02,\n",
            "        9.2468750e+01, 6.7656250e+01, 5.6781250e+01, 1.7687500e+01],\n",
            "       [1.1250000e+01, 3.0531250e+01, 3.5687500e+01, 4.6281250e+01,\n",
            "        8.4281250e+01, 1.0359375e+02, 1.1325000e+02, 9.3781250e+01,\n",
            "        1.2184375e+02, 1.4709375e+02, 1.5878125e+02, 1.5853125e+02,\n",
            "        1.6109375e+02, 1.6171875e+02, 1.5831250e+02, 1.5656250e+02,\n",
            "        1.5906250e+02, 1.7250000e+02, 1.7578125e+02, 1.6787500e+02,\n",
            "        1.0328125e+02, 1.3312500e+02, 1.3059375e+02, 1.2462500e+02,\n",
            "        9.0625000e+01, 5.7937500e+01, 4.5593750e+01, 1.7843750e+01],\n",
            "       [6.0625000e+00, 2.6281250e+01, 3.4062500e+01, 5.0468750e+01,\n",
            "        8.9625000e+01, 1.0981250e+02, 1.1656250e+02, 9.1750000e+01,\n",
            "        1.3050000e+02, 1.5021875e+02, 1.6059375e+02, 1.6015625e+02,\n",
            "        1.5834375e+02, 1.5846875e+02, 1.6134375e+02, 1.6337500e+02,\n",
            "        1.5668750e+02, 1.6340625e+02, 1.6259375e+02, 1.5562500e+02,\n",
            "        9.2937500e+01, 1.2434375e+02, 1.2559375e+02, 1.1771875e+02,\n",
            "        8.4156250e+01, 5.5468750e+01, 3.6593750e+01, 1.4750000e+01],\n",
            "       [4.1562500e+00, 1.7156250e+01, 2.3593750e+01, 5.2281250e+01,\n",
            "        8.9656250e+01, 1.0078125e+02, 1.0940625e+02, 9.2687500e+01,\n",
            "        1.3450000e+02, 1.5275000e+02, 1.6212500e+02, 1.6275000e+02,\n",
            "        1.6693750e+02, 1.6175000e+02, 1.5837500e+02, 1.5718750e+02,\n",
            "        1.5303125e+02, 1.6725000e+02, 1.6271875e+02, 1.5534375e+02,\n",
            "        9.9281250e+01, 1.2168750e+02, 1.2609375e+02, 1.1903125e+02,\n",
            "        8.1750000e+01, 5.4750000e+01, 3.3531250e+01, 8.5937500e+00],\n",
            "       [8.4375000e+00, 1.7250000e+01, 2.6468750e+01, 5.0750000e+01,\n",
            "        7.8250000e+01, 9.7000000e+01, 1.0178125e+02, 9.6250000e+01,\n",
            "        1.4146875e+02, 1.5234375e+02, 1.6228125e+02, 1.6109375e+02,\n",
            "        1.6106250e+02, 1.5037500e+02, 1.4409375e+02, 1.4868750e+02,\n",
            "        1.4790625e+02, 1.6028125e+02, 1.5268750e+02, 1.5184375e+02,\n",
            "        9.6500000e+01, 1.1109375e+02, 1.1681250e+02, 1.0381250e+02,\n",
            "        7.3125000e+01, 4.6656250e+01, 2.7437500e+01, 5.9375000e+00],\n",
            "       [8.5312500e+00, 1.8406250e+01, 2.4218750e+01, 4.9625000e+01,\n",
            "        7.1812500e+01, 9.1781250e+01, 1.0293750e+02, 9.5468750e+01,\n",
            "        1.3715625e+02, 1.4796875e+02, 1.5493750e+02, 1.5178125e+02,\n",
            "        1.4728125e+02, 1.4165625e+02, 1.3821875e+02, 1.4525000e+02,\n",
            "        1.4556250e+02, 1.5268750e+02, 1.4596875e+02, 1.4578125e+02,\n",
            "        8.9343750e+01, 9.5156250e+01, 1.0271875e+02, 9.2281250e+01,\n",
            "        6.5937500e+01, 4.8031250e+01, 2.7406250e+01, 4.2500000e+00],\n",
            "       [8.4375000e-01, 1.3562500e+01, 2.0187500e+01, 3.8937500e+01,\n",
            "        6.4062500e+01, 8.7687500e+01, 9.1750000e+01, 8.6781250e+01,\n",
            "        1.2846875e+02, 1.4262500e+02, 1.4803125e+02, 1.4893750e+02,\n",
            "        1.4068750e+02, 1.3525000e+02, 1.3465625e+02, 1.4793750e+02,\n",
            "        1.4315625e+02, 1.4653125e+02, 1.3846875e+02, 1.3903125e+02,\n",
            "        8.5156250e+01, 8.2843750e+01, 9.5875000e+01, 9.1406250e+01,\n",
            "        5.6906250e+01, 3.7281250e+01, 1.6343750e+01, 7.8125000e-01],\n",
            "       [6.2500000e-02, 5.6250000e-01, 1.4718750e+01, 4.1281250e+01,\n",
            "        6.2343750e+01, 7.8750000e+01, 8.6062500e+01, 8.5906250e+01,\n",
            "        1.2243750e+02, 1.3065625e+02, 1.3528125e+02, 1.3440625e+02,\n",
            "        1.2846875e+02, 1.2418750e+02, 1.3300000e+02, 1.3900000e+02,\n",
            "        1.2750000e+02, 1.3437500e+02, 1.3409375e+02, 1.3750000e+02,\n",
            "        7.9406250e+01, 7.7687500e+01, 9.5000000e+01, 8.6625000e+01,\n",
            "        5.5593750e+01, 3.1031250e+01, 9.3125000e+00, 5.3125000e-01],\n",
            "       [6.2500000e-02, 0.0000000e+00, 3.8750000e+00, 3.5843750e+01,\n",
            "        6.0312500e+01, 8.1562500e+01, 8.7156250e+01, 8.3468750e+01,\n",
            "        1.1903125e+02, 1.3034375e+02, 1.3356250e+02, 1.3625000e+02,\n",
            "        1.3187500e+02, 1.3140625e+02, 1.3009375e+02, 1.2815625e+02,\n",
            "        1.2331250e+02, 1.2993750e+02, 1.2903125e+02, 1.3303125e+02,\n",
            "        8.0000000e+01, 7.5687500e+01, 9.5906250e+01, 8.6031250e+01,\n",
            "        5.7968750e+01, 2.3187500e+01, 6.2500000e+00, 0.0000000e+00],\n",
            "       [5.3125000e-01, 4.8125000e+00, 5.9375000e+00, 2.8125000e+01,\n",
            "        6.0562500e+01, 7.7593750e+01, 7.3718750e+01, 7.2656250e+01,\n",
            "        1.0296875e+02, 1.1384375e+02, 1.1668750e+02, 1.2053125e+02,\n",
            "        1.1359375e+02, 1.0428125e+02, 1.0150000e+02, 1.0062500e+02,\n",
            "        1.0153125e+02, 1.0762500e+02, 1.0575000e+02, 1.1084375e+02,\n",
            "        5.9250000e+01, 5.1718750e+01, 8.4125000e+01, 7.2718750e+01,\n",
            "        4.1437500e+01, 7.5625000e+00, 8.1250000e-01, 7.5000000e-01],\n",
            "       [1.8437500e+00, 6.3437500e+00, 6.2187500e+00, 1.0093750e+01,\n",
            "        4.4937500e+01, 6.1468750e+01, 5.0468750e+01, 4.6812500e+01,\n",
            "        7.7437500e+01, 8.5468750e+01, 9.2312500e+01, 9.8125000e+01,\n",
            "        9.1468750e+01, 8.5562500e+01, 9.6718750e+01, 8.9187500e+01,\n",
            "        9.0906250e+01, 9.9093750e+01, 9.6750000e+01, 9.1406250e+01,\n",
            "        4.0093750e+01, 3.6468750e+01, 6.1875000e+01, 5.4937500e+01,\n",
            "        1.6375000e+01, 3.9687500e+00, 5.2187500e+00, 2.2812500e+00],\n",
            "       [0.0000000e+00, 0.0000000e+00, 3.1250000e-02, 7.5000000e-01,\n",
            "        5.8750000e+00, 1.2125000e+01, 9.9062500e+00, 9.9375000e+00,\n",
            "        2.0718750e+01, 2.7781250e+01, 3.5906250e+01, 4.1250000e+01,\n",
            "        4.1562500e+01, 3.8312500e+01, 4.6343750e+01, 4.3593750e+01,\n",
            "        4.0718750e+01, 4.1593750e+01, 3.3625000e+01, 2.3062500e+01,\n",
            "        7.5937500e+00, 4.6562500e+00, 2.0218750e+01, 1.9093750e+01,\n",
            "        1.9375000e+00, 6.2500000e-02, 0.0000000e+00, 0.0000000e+00]],\n",
            "      dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHZAcedWZvw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d03be8-6b23-4ec3-d492-d67bd6c6459b"
      },
      "source": [
        "\n",
        "(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "print(x_train.shape)\n",
        "input_shape = x_train.shape[1:] #[1:] znaczy wszystkie featury\n",
        "print(input_shape)\n",
        "classes = 10\n",
        "\n",
        "# Create a Normalization layer and set its internal state using the training data\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(x_train)\n",
        "\n",
        "# Create a model that include the normalization layer\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = normalizer(inputs)\n",
        "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Train the model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 3072)\n",
            "(3072,)\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.1299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ad356cd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw3thVgSZwdp"
      },
      "source": [
        "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
        "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
        "                               axis=0).astype(np.float32) # jedna tabela ze wszystkimi dziesięcioma zdjęciami\n",
        "class Standardization(keras.layers.Layer):\n",
        "    def adapt(self, data_sample):\n",
        "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
        "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
        "        #print(self.means_)\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
        "\n",
        "standardization = Standardization(input_shape=[28, 28])\n",
        "standardization.adapt(sample_images)\n",
        "\n",
        "normalizer = preprocessing.Normalization(axis=(1,2)) #pomijamy osie 1 i 2 --> zostawiamy oś 0\n",
        "normalizer.adapt(sample_images)\n",
        "\n",
        "\"\"\"\n",
        "print(normalizer.mean-standardization.means_) #to samo!! ale osie inne\n",
        "# layers.normalization wymaga by podać osie które NIE będą normalizowane\n",
        "print(tf.math.sqrt(normalizer.variance)- standardization.stds_)\n",
        "# też to samo. dlaczego zatem tak różne są\n",
        "\n",
        "\"\"\" \n",
        "train_batches = train_set.take(20).map(lambda image, label: image)\n",
        "train_ =np.concatenate(list(train_batches.as_numpy_iterator()),\n",
        "                               axis=0).astype(np.float32) #mikro train set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNvoQJAy1kOM"
      },
      "source": [
        "standardization(train_)-normalizer(train_) # wygląda dobrze, wartości praktycznie równe 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJJ-EDH4uTz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690f4293-5003-4aae-f24b-aaceee327ef6"
      },
      "source": [
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    standardization,\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model2 = keras.models.Sequential([\n",
        "    normalizer,\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "history = model.fit(train_set, epochs=5, validation_data=valid_set,\n",
        "          callbacks=[])\n",
        "\n",
        "print(\"#####\")\n",
        "\n",
        "\n",
        "history2= model2.fit(train_set, epochs=5, validation_data=valid_set,\n",
        "          callbacks=[])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4631 - accuracy: 0.8408 - val_loss: 0.3524 - val_accuracy: 0.8723\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3422 - accuracy: 0.8767 - val_loss: 0.3109 - val_accuracy: 0.8849\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3019 - accuracy: 0.8912 - val_loss: 0.2574 - val_accuracy: 0.9095\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2741 - accuracy: 0.9006 - val_loss: 0.2375 - val_accuracy: 0.9119\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2548 - accuracy: 0.9078 - val_loss: 0.2195 - val_accuracy: 0.9195\n",
            "#####\n",
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4668 - accuracy: 0.8401 - val_loss: 0.3465 - val_accuracy: 0.8756\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3382 - accuracy: 0.8785 - val_loss: 0.2821 - val_accuracy: 0.8987\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3015 - accuracy: 0.8914 - val_loss: 0.2651 - val_accuracy: 0.9031\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2712 - accuracy: 0.9005 - val_loss: 0.2458 - val_accuracy: 0.9105\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2504 - accuracy: 0.9083 - val_loss: 0.2177 - val_accuracy: 0.9213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMb5PfMpuY14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a988e97f-23f0-4951-8284-c00143e1c903"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "class Standardization(keras.layers.Layer):\n",
        "    def adapt(self, data_sample):\n",
        "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
        "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
        "\n",
        "standardization = Standardization(input_shape=[28, 28])\n",
        "# or perhaps soon:\n",
        "#standardization = keras.layers.Normalization()\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "normalizer = preprocessing.Normalization(axis=(1,2))\n",
        "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
        "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
        "                               axis=0).astype(np.float32)\n",
        "standardization.adapt(sample_images)\n",
        "normalizer.adapt(sample_images)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    normalizer,\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
        "          callbacks=[])\n",
        "\n",
        "\n",
        "model2 = keras.models.Sequential([\n",
        "    normalizer,\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model2.fit(train_set, epochs=5, validation_data=valid_set,\n",
        "          callbacks=[])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4613 - accuracy: 0.8431 - val_loss: 0.3730 - val_accuracy: 0.8714\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3441 - accuracy: 0.8778 - val_loss: 0.2926 - val_accuracy: 0.8961\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3054 - accuracy: 0.8929 - val_loss: 0.2533 - val_accuracy: 0.9083\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2772 - accuracy: 0.9011 - val_loss: 0.2603 - val_accuracy: 0.9049\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2631 - accuracy: 0.9075 - val_loss: 0.2319 - val_accuracy: 0.9141\n",
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4695 - accuracy: 0.8411 - val_loss: 0.3453 - val_accuracy: 0.8766\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3531 - accuracy: 0.8796 - val_loss: 0.2971 - val_accuracy: 0.8962\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3092 - accuracy: 0.8917 - val_loss: 0.2525 - val_accuracy: 0.9073\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2827 - accuracy: 0.9003 - val_loss: 0.2315 - val_accuracy: 0.9174\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2529 - accuracy: 0.9077 - val_loss: 0.2278 - val_accuracy: 0.9167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ad371acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f6v-g2_AFOU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}