{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH16_SET10_with_notes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN44tu1zlVUkIcyseO5J1D5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qamtam/Hands-on-machine-learning/blob/main/CH16_SET10_with_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re5vTSzcVCHb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLJggXVXVcTK"
      },
      "source": [
        "#data prep game plan\n",
        "#1 add a start (<sos>), end (<eos>) token \n",
        "#2 clean the sentences with removing all special characters\n",
        "#3 embed the word index and reverse word index (word -> id) and (id -> word)\n",
        "#4 pad the sentences to max length\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaWWAtRTWmzB",
        "outputId": "1a62e223-5812-42d0-fc6a-74d009104431"
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvllH0f6WtC1"
      },
      "source": [
        "# Convert the unicode file to ascii\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "  # print(s)\n",
        "  # print(''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')) visibly identical\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn') #mn is a 'nonspacing mark' category like the ` above a in a la\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  \n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71xOGya4YDdg",
        "outputId": "6003b3e1-9ede-4ce8-d563-ccd9a285b7af"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "\n",
        "print(preprocess_sentence(sp_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>  ¿ puedo tomar prestado este libro ?  <end>\n",
            "b'<start>  \\xc2\\xbf puedo tomar prestado este libro ?  <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9y1Tg53YSMp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yadWhywJdUI7"
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n') # otwórz, przeczytaj, usuń nadmiarowe spacje, oddzielamy enterem i te oddzielone ładujemy do jednej zmiennej\n",
        "  #print(lines[55]) ## No way!\tDe ninguna manera.\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]] # tabulator oddziela angielski od hiszpańskiego\n",
        "\n",
        "  return zip(*word_pairs) \n",
        "  #* to operator unzippowania! -> mamy zatem jedną krotkę (en, sp) w której każdy element jest listą słów, a wyrażenia mogą być dłuższe (he is mean)\n",
        "  '''\n",
        ">>> letters = ['b', 'a', 'd', 'c']\n",
        ">>> numbers = [2, 4, 3, 1]\n",
        ">>> data = sorted(zip(letters, numbers))  # Sort by letters\n",
        ">>> data\n",
        "[('a', 4), ('b', 2), ('c', 1), ('d', 3)]\n",
        "\n",
        ">>> pairs = [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n",
        ">>> numbers, letters = zip(*pairs)\n",
        ">>> numbers\n",
        "(1, 2, 3, 4)\n",
        ">>> letters\n",
        "('a', 'b', 'c', 'd')\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7oiwTmada1y",
        "outputId": "c23c1c15-d145-4f1f-b00b-853ecf15f897"
      },
      "source": [
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[:20])\n",
        "print(sp[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tVaya.\n",
            "('<start> go .  <end>', '<start> go .  <end>', '<start> go .  <end>', '<start> go .  <end>', '<start> hi .  <end>', '<start> run !  <end>', '<start> run .  <end>', '<start> who ?  <end>', '<start> fire !  <end>', '<start> fire !  <end>', '<start> fire !  <end>', '<start> help !  <end>', '<start> help !  <end>', '<start> help !  <end>', '<start> jump !  <end>', '<start> jump .  <end>', '<start> stop !  <end>', '<start> stop !  <end>', '<start> stop !  <end>', '<start> wait !  <end>')\n",
            "('<start> ve .  <end>', '<start> vete .  <end>', '<start> vaya .  <end>', '<start> vayase .  <end>', '<start> hola .  <end>', '<start>  corre !  <end>', '<start> corred .  <end>', '<start>  ¿ quien ?  <end>', '<start>  fuego !  <end>', '<start>  incendio !  <end>', '<start>  disparad !  <end>', '<start>  ayuda !  <end>', '<start>  socorro ! auxilio !  <end>', '<start>  auxilio !  <end>', '<start>  salta !  <end>', '<start> salte .  <end>', '<start>  parad !  <end>', '<start>  para !  <end>', '<start>  pare !  <end>', '<start>  espera !  <end>')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvb2acKsdbvk"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='') # pusty tokenizator\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  # stwórz id dla słów w tekście (dopasowanie tokenizatora)\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  # dummy tensor na pojedynczych słowach języka (go => 1 stay => 2  etc). Pasuje też do całych zdań, ale tu zdań nie ma, zatem równie dobrze mozna to nazwać words_to_numbers czy coś\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  # wyrównanie długości elementów tensora do najdłuższego\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bez5DejIiDUM"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NshZgHz7iPMz",
        "outputId": "de1d8f0a-d851-44f0-c261-5c9f6bb64da5"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pip1HWwYifLh"
      },
      "source": [
        "#tf.data\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train) #rozmiar bufora do przemieszania, przemiesza oczywiście jednocześnie odpowiednie pary zachowując sens\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1 # inp_lang to sam tokenizer, word index to dict {'una' : 21, ... }\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwn6UgCWn_gT",
        "outputId": "9b6cfa49-c75d-4d8c-9703-7fa6831753dc"
      },
      "source": [
        "inp_lang.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<start>': 1,\n",
              " '<end>': 2,\n",
              " '.': 3,\n",
              " 'tom': 4,\n",
              " '?': 5,\n",
              " '¿': 6,\n",
              " 'es': 7,\n",
              " 'no': 8,\n",
              " 'el': 9,\n",
              " 'a': 10,\n",
              " 'que': 11,\n",
              " 'me': 12,\n",
              " 'la': 13,\n",
              " 'de': 14,\n",
              " 'un': 15,\n",
              " 'esta': 16,\n",
              " 'se': 17,\n",
              " 'lo': 18,\n",
              " 'mi': 19,\n",
              " 'en': 20,\n",
              " 'una': 21,\n",
              " 'por': 22,\n",
              " 'te': 23,\n",
              " 'estoy': 24,\n",
              " 'ella': 25,\n",
              " 'yo': 26,\n",
              " '!': 27,\n",
              " 'eso': 28,\n",
              " 'le': 29,\n",
              " 'esto': 30,\n",
              " 'tu': 31,\n",
              " ',': 32,\n",
              " 'los': 33,\n",
              " 'aqui': 34,\n",
              " 'soy': 35,\n",
              " 'muy': 36,\n",
              " 'tengo': 37,\n",
              " 'puedo': 38,\n",
              " 'las': 39,\n",
              " 'gusta': 40,\n",
              " 'mary': 41,\n",
              " 'tiene': 42,\n",
              " 'son': 43,\n",
              " 'con': 44,\n",
              " 'como': 45,\n",
              " 'quien': 46,\n",
              " 'estaba': 47,\n",
              " 'su': 48,\n",
              " 'este': 49,\n",
              " 'favor': 50,\n",
              " 'estas': 51,\n",
              " 'eres': 52,\n",
              " 'quiero': 53,\n",
              " 'ellos': 54,\n",
              " 'fue': 55,\n",
              " 'bien': 56,\n",
              " 'casa': 57,\n",
              " 'ahora': 58,\n",
              " 'tomas': 59,\n",
              " 'donde': 60,\n",
              " 'mas': 61,\n",
              " 'estan': 62,\n",
              " 'nos': 63,\n",
              " 'he': 64,\n",
              " 'solo': 65,\n",
              " 'puede': 66,\n",
              " 'ha': 67,\n",
              " 'era': 68,\n",
              " 'todos': 69,\n",
              " 'al': 70,\n",
              " 'para': 71,\n",
              " 'ir': 72,\n",
              " 'tan': 73,\n",
              " 'todo': 74,\n",
              " 'estamos': 75,\n",
              " 'necesito': 76,\n",
              " 'ya': 77,\n",
              " 'nadie': 78,\n",
              " 'puedes': 79,\n",
              " 'trabajo': 80,\n",
              " 'voy': 81,\n",
              " 'usted': 82,\n",
              " 'tienes': 83,\n",
              " 'demasiado': 84,\n",
              " 'ese': 85,\n",
              " 'nada': 86,\n",
              " 'y': 87,\n",
              " 'hay': 88,\n",
              " 'mucho': 89,\n",
              " 'nunca': 90,\n",
              " 'hizo': 91,\n",
              " 'perro': 92,\n",
              " 'esa': 93,\n",
              " 'algo': 94,\n",
              " 'libro': 95,\n",
              " 'hoy': 96,\n",
              " 'poco': 97,\n",
              " 'dos': 98,\n",
              " 'parece': 99,\n",
              " 'todavia': 100,\n",
              " 'dinero': 101,\n",
              " 'tiempo': 102,\n",
              " 'nuevo': 103,\n",
              " 'sabe': 104,\n",
              " 'somos': 105,\n",
              " 'quiere': 106,\n",
              " 'mis': 107,\n",
              " 'gustan': 108,\n",
              " 'ser': 109,\n",
              " 'nosotros': 110,\n",
              " 'vez': 111,\n",
              " 'coche': 112,\n",
              " 'estar': 113,\n",
              " 'sos': 114,\n",
              " 'feliz': 115,\n",
              " 'va': 116,\n",
              " 'buen': 117,\n",
              " 'tarde': 118,\n",
              " 'ti': 119,\n",
              " 'ahi': 120,\n",
              " 'frances': 121,\n",
              " 'hablar': 122,\n",
              " 'hacer': 123,\n",
              " 'verdad': 124,\n",
              " 'hace': 125,\n",
              " 'creo': 126,\n",
              " 'tenemos': 127,\n",
              " 'ayuda': 128,\n",
              " 'alli': 129,\n",
              " 'boston': 130,\n",
              " 'hombre': 131,\n",
              " 'has': 132,\n",
              " 'deja': 133,\n",
              " 'vi': 134,\n",
              " 've': 135,\n",
              " 'mal': 136,\n",
              " 'alguien': 137,\n",
              " 'auto': 138,\n",
              " 'vamos': 139,\n",
              " 'si': 140,\n",
              " 'mejor': 141,\n",
              " 'siento': 142,\n",
              " 'podria': 143,\n",
              " 'podemos': 144,\n",
              " 'cuando': 145,\n",
              " 'hice': 146,\n",
              " 'vida': 147,\n",
              " 'odio': 148,\n",
              " 'dia': 149,\n",
              " 'conmigo': 150,\n",
              " 'siempre': 151,\n",
              " 'les': 152,\n",
              " 'encanta': 153,\n",
              " 'otra': 154,\n",
              " 'dejame': 155,\n",
              " 'rapido': 156,\n",
              " 'cual': 157,\n",
              " 'ustedes': 158,\n",
              " 'vino': 159,\n",
              " 'tenia': 160,\n",
              " 'puerta': 161,\n",
              " 'bueno': 162,\n",
              " 'ver': 163,\n",
              " 'hacerlo': 164,\n",
              " 'ven': 165,\n",
              " 'tambien': 166,\n",
              " 'os': 167,\n",
              " 'comer': 168,\n",
              " 'buena': 169,\n",
              " 'sus': 170,\n",
              " 'deberia': 171,\n",
              " 'dijo': 172,\n",
              " 'listo': 173,\n",
              " 'padre': 174,\n",
              " 'habitacion': 175,\n",
              " 'habla': 176,\n",
              " 'nuestro': 177,\n",
              " 'realmente': 178,\n",
              " 'ayudar': 179,\n",
              " 'queria': 180,\n",
              " 'hecho': 181,\n",
              " 'mismo': 182,\n",
              " 'nadar': 183,\n",
              " 'cansado': 184,\n",
              " 'ocupado': 185,\n",
              " 'del': 186,\n",
              " 'acabo': 187,\n",
              " 'razon': 188,\n",
              " 'grande': 189,\n",
              " 'noche': 190,\n",
              " 'gracias': 191,\n",
              " 'mira': 192,\n",
              " 'gato': 193,\n",
              " 'miedo': 194,\n",
              " 'manana': 195,\n",
              " 'acuerdo': 196,\n",
              " 'debo': 197,\n",
              " 'cama': 198,\n",
              " 'dije': 199,\n",
              " 'tus': 200,\n",
              " 'espera': 201,\n",
              " 'visto': 202,\n",
              " 'mio': 203,\n",
              " 'tal': 204,\n",
              " 'bastante': 205,\n",
              " 'alto': 206,\n",
              " 'veo': 207,\n",
              " 'ellas': 208,\n",
              " 'necesita': 209,\n",
              " 'dame': 210,\n",
              " 'idea': 211,\n",
              " 'amigos': 212,\n",
              " 'hemos': 213,\n",
              " 'quieres': 214,\n",
              " 'pareces': 215,\n",
              " 'casi': 216,\n",
              " 'estado': 217,\n",
              " 'fui': 218,\n",
              " 'hambre': 219,\n",
              " 'dio': 220,\n",
              " 'agua': 221,\n",
              " 'sabes': 222,\n",
              " 'sabia': 223,\n",
              " 'uno': 224,\n",
              " 'comida': 225,\n",
              " 'problema': 226,\n",
              " 'facil': 227,\n",
              " 'frio': 228,\n",
              " 'fuera': 229,\n",
              " 'lunes': 230,\n",
              " 'amigo': 231,\n",
              " 'duele': 232,\n",
              " 'dejo': 233,\n",
              " 'conozco': 234,\n",
              " 'estos': 235,\n",
              " 'vio': 236,\n",
              " 'madre': 237,\n",
              " 'pronto': 238,\n",
              " 'anos': 239,\n",
              " 'nino': 240,\n",
              " 'loco': 241,\n",
              " 'haz': 242,\n",
              " 'dormir': 243,\n",
              " 'libros': 244,\n",
              " 'puso': 245,\n",
              " 'mano': 246,\n",
              " 'sin': 247,\n",
              " 'television': 248,\n",
              " 'vive': 249,\n",
              " 'ojos': 250,\n",
              " 'menos': 251,\n",
              " 'cantar': 252,\n",
              " 'estuvo': 253,\n",
              " 'hora': 254,\n",
              " 'enfermo': 255,\n",
              " 'amo': 256,\n",
              " 'seguro': 257,\n",
              " 'mundo': 258,\n",
              " 'tienen': 259,\n",
              " 'pelo': 260,\n",
              " 'murio': 261,\n",
              " 'perros': 262,\n",
              " 'perdido': 263,\n",
              " 'joven': 264,\n",
              " 'compre': 265,\n",
              " 'mujer': 266,\n",
              " 'maria': 267,\n",
              " 'nombre': 268,\n",
              " 'contigo': 269,\n",
              " 'viejo': 270,\n",
              " 'hablo': 271,\n",
              " 'triste': 272,\n",
              " 'entrar': 273,\n",
              " 'espero': 274,\n",
              " 'sueno': 275,\n",
              " 'suerte': 276,\n",
              " 'necesitamos': 277,\n",
              " 'estais': 278,\n",
              " 'haciendo': 279,\n",
              " 'reloj': 280,\n",
              " 'perdi': 281,\n",
              " 'hasta': 282,\n",
              " 'momento': 283,\n",
              " 'toma': 284,\n",
              " 'tres': 285,\n",
              " 'queremos': 286,\n",
              " 'sigue': 287,\n",
              " 'viene': 288,\n",
              " 'escuela': 289,\n",
              " 'llave': 290,\n",
              " 'culpa': 291,\n",
              " 'historia': 292,\n",
              " 'vete': 293,\n",
              " 'fuerte': 294,\n",
              " 'calor': 295,\n",
              " 'vas': 296,\n",
              " 'cafe': 297,\n",
              " 'gran': 298,\n",
              " 'temprano': 299,\n",
              " 'cerca': 300,\n",
              " 'cerveza': 301,\n",
              " 'llorar': 302,\n",
              " 'irme': 303,\n",
              " 'jugar': 304,\n",
              " 'perdio': 305,\n",
              " 'ido': 306,\n",
              " 'sola': 307,\n",
              " 'venir': 308,\n",
              " 'vivo': 309,\n",
              " 'di': 310,\n",
              " 'necesitas': 311,\n",
              " 'seas': 312,\n",
              " 'hijo': 313,\n",
              " 'media': 314,\n",
              " 'cuanto': 315,\n",
              " 'leer': 316,\n",
              " 'ingles': 317,\n",
              " 'semana': 318,\n",
              " 'mia': 319,\n",
              " 'trabaja': 320,\n",
              " 'cosas': 321,\n",
              " 'gusto': 322,\n",
              " 'pagar': 323,\n",
              " 'pueden': 324,\n",
              " 'tuve': 325,\n",
              " 'han': 326,\n",
              " 'gente': 327,\n",
              " 'manos': 328,\n",
              " 'libre': 329,\n",
              " 'salir': 330,\n",
              " 'esperar': 331,\n",
              " 'estupido': 332,\n",
              " 'leche': 333,\n",
              " 'cierto': 334,\n",
              " 'lista': 335,\n",
              " 'dificil': 336,\n",
              " 'muerto': 337,\n",
              " 'llama': 338,\n",
              " 'borracho': 339,\n",
              " 'vale': 340,\n",
              " 'bebe': 341,\n",
              " 'camino': 342,\n",
              " 'duro': 343,\n",
              " 'vos': 344,\n",
              " 'estaban': 345,\n",
              " 'zapatos': 346,\n",
              " 'sea': 347,\n",
              " 'llego': 348,\n",
              " 'primero': 349,\n",
              " 'hazlo': 350,\n",
              " 'trabajar': 351,\n",
              " 'quedate': 352,\n",
              " 'comiendo': 353,\n",
              " 'decir': 354,\n",
              " 'esos': 355,\n",
              " 'minuto': 356,\n",
              " 'bicicleta': 357,\n",
              " 'pasa': 358,\n",
              " 'lado': 359,\n",
              " 'quedo': 360,\n",
              " 'asi': 361,\n",
              " 'gatos': 362,\n",
              " 'o': 363,\n",
              " 'hermana': 364,\n",
              " 'familia': 365,\n",
              " 'respuesta': 366,\n",
              " 'ayer': 367,\n",
              " 'rico': 368,\n",
              " 'divertido': 369,\n",
              " 'extrano': 370,\n",
              " 'vuelve': 371,\n",
              " 'hacia': 372,\n",
              " 'persona': 373,\n",
              " 'llamo': 374,\n",
              " 'mala': 375,\n",
              " 'ninos': 376,\n",
              " 'sombrero': 377,\n",
              " 'saben': 378,\n",
              " 'hablando': 379,\n",
              " 'quieren': 380,\n",
              " 'ama': 381,\n",
              " 'ves': 382,\n",
              " 'cabeza': 383,\n",
              " 'debe': 384,\n",
              " 'volvio': 385,\n",
              " 'malo': 386,\n",
              " 'funciona': 387,\n",
              " 'aca': 388,\n",
              " 'da': 389,\n",
              " 'chico': 390,\n",
              " 'caja': 391,\n",
              " 'queda': 392,\n",
              " 'boca': 393,\n",
              " 'telefono': 394,\n",
              " 'vuelta': 395,\n",
              " 'paso': 396,\n",
              " 'cuenta': 397,\n",
              " 'felices': 398,\n",
              " 'empezo': 399,\n",
              " 'plan': 400,\n",
              " 'juego': 401,\n",
              " 'estabas': 402,\n",
              " 'comio': 403,\n",
              " 'esperando': 404,\n",
              " 'bajo': 405,\n",
              " 'estabamos': 406,\n",
              " 'vosotros': 407,\n",
              " 'abogado': 408,\n",
              " 'cara': 409,\n",
              " 'otro': 410,\n",
              " 'lleva': 411,\n",
              " 'mintiendo': 412,\n",
              " 'inteligente': 413,\n",
              " 'hiciste': 414,\n",
              " 'edad': 415,\n",
              " 'parar': 416,\n",
              " 'deberiamos': 417,\n",
              " 'verte': 418,\n",
              " 'tenis': 419,\n",
              " 'estuve': 420,\n",
              " 'importante': 421,\n",
              " 'esposa': 422,\n",
              " 'debes': 423,\n",
              " 'sal': 424,\n",
              " 'entiendo': 425,\n",
              " 'tome': 426,\n",
              " 'ocupada': 427,\n",
              " 'encontre': 428,\n",
              " 'amor': 429,\n",
              " 'encantan': 430,\n",
              " 'vuestro': 431,\n",
              " 'secreto': 432,\n",
              " 'suficiente': 433,\n",
              " 'palabra': 434,\n",
              " 'bailar': 435,\n",
              " 'sido': 436,\n",
              " 'manzana': 437,\n",
              " 'ni': 438,\n",
              " 'nuestra': 439,\n",
              " 'cierra': 440,\n",
              " 'venga': 441,\n",
              " 'cuidado': 442,\n",
              " 'come': 443,\n",
              " 'estare': 444,\n",
              " 'ciudad': 445,\n",
              " 'podes': 446,\n",
              " 'conoces': 447,\n",
              " 'lugar': 448,\n",
              " 'profesor': 449,\n",
              " 'habia': 450,\n",
              " 'ojala': 451,\n",
              " 'queres': 452,\n",
              " 'guerra': 453,\n",
              " 'aun': 454,\n",
              " 'camisa': 455,\n",
              " 'escucha': 456,\n",
              " 'gano': 457,\n",
              " 'acaso': 458,\n",
              " 'asiento': 459,\n",
              " 'dormido': 460,\n",
              " 'equivocado': 461,\n",
              " 'leyendo': 462,\n",
              " 'odia': 463,\n",
              " 'hermano': 464,\n",
              " 'afuera': 465,\n",
              " 'hijos': 466,\n",
              " 'toda': 467,\n",
              " 'sento': 468,\n",
              " 'despierto': 469,\n",
              " 'suyo': 470,\n",
              " 'salio': 471,\n",
              " 'carne': 472,\n",
              " 'ayudo': 473,\n",
              " 'levanto': 474,\n",
              " 'dice': 475,\n",
              " 'carta': 476,\n",
              " 'carro': 477,\n",
              " 'ambos': 478,\n",
              " 'pequeno': 479,\n",
              " 'bano': 480,\n",
              " 'cuarto': 481,\n",
              " 'llaves': 482,\n",
              " 'juntos': 483,\n",
              " 'estudiar': 484,\n",
              " 'parecia': 485,\n",
              " 'mesa': 486,\n",
              " 'parte': 487,\n",
              " 'correr': 488,\n",
              " 'deje': 489,\n",
              " 'hagas': 490,\n",
              " 'lejos': 491,\n",
              " 'termino': 492,\n",
              " 'tren': 493,\n",
              " 'importa': 494,\n",
              " 'dios': 495,\n",
              " 'hare': 496,\n",
              " 'grito': 497,\n",
              " 'ganar': 498,\n",
              " 'musica': 499,\n",
              " 'broma': 500,\n",
              " 'cancion': 501,\n",
              " 'digas': 502,\n",
              " 'tipo': 503,\n",
              " 'dolor': 504,\n",
              " 'sois': 505,\n",
              " 'conocen': 506,\n",
              " 'cuantos': 507,\n",
              " 'conoce': 508,\n",
              " 'tenes': 509,\n",
              " 'policia': 510,\n",
              " 'acaba': 511,\n",
              " 'seis': 512,\n",
              " 'suena': 513,\n",
              " 'sobre': 514,\n",
              " 'antes': 515,\n",
              " 'trabajando': 516,\n",
              " 'justo': 517,\n",
              " 'ello': 518,\n",
              " 'llame': 519,\n",
              " 'herido': 520,\n",
              " 'despues': 521,\n",
              " 'enojado': 522,\n",
              " 'tuyo': 523,\n",
              " 'dentro': 524,\n",
              " 'voz': 525,\n",
              " 'trampa': 526,\n",
              " 'tuvo': 527,\n",
              " 'equipo': 528,\n",
              " 'cocinar': 529,\n",
              " 'bolsa': 530,\n",
              " 'peligro': 531,\n",
              " 'chica': 532,\n",
              " 'canadiense': 533,\n",
              " 'amiga': 534,\n",
              " 'ropa': 535,\n",
              " 'serio': 536,\n",
              " 'gordo': 537,\n",
              " 'senti': 538,\n",
              " 'ten': 539,\n",
              " 'van': 540,\n",
              " 'caminar': 541,\n",
              " 'podeis': 542,\n",
              " 'teneis': 543,\n",
              " 'venido': 544,\n",
              " 'oido': 545,\n",
              " 'listos': 546,\n",
              " 'dias': 547,\n",
              " 'boligrafo': 548,\n",
              " 'reglas': 549,\n",
              " 'doctor': 550,\n",
              " 'llorando': 551,\n",
              " 'bromeando': 552,\n",
              " 'morir': 553,\n",
              " 'idiota': 554,\n",
              " 'error': 555,\n",
              " 'usar': 556,\n",
              " 'nina': 557,\n",
              " 'volver': 558,\n",
              " 'mucha': 559,\n",
              " 'padres': 560,\n",
              " 'largo': 561,\n",
              " 'despacio': 562,\n",
              " 'segundo': 563,\n",
              " 'olvide': 564,\n",
              " 'lloro': 565,\n",
              " 'echo': 566,\n",
              " 'paciente': 567,\n",
              " 'hombres': 568,\n",
              " 'amable': 569,\n",
              " 'sentia': 570,\n",
              " 'fin': 571,\n",
              " 'encontrar': 572,\n",
              " 'escucho': 573,\n",
              " 'pescado': 574,\n",
              " 'ingenuo': 575,\n",
              " 'casado': 576,\n",
              " 'aburrido': 577,\n",
              " 'saber': 578,\n",
              " 'alla': 579,\n",
              " 'quienes': 580,\n",
              " 'mujeres': 581,\n",
              " 'taxi': 582,\n",
              " 'tanto': 583,\n",
              " 'estudiando': 584,\n",
              " 'fumar': 585,\n",
              " 'dime': 586,\n",
              " 'autobus': 587,\n",
              " 'estudiante': 588,\n",
              " 'siguio': 589,\n",
              " 'deberias': 590,\n",
              " 'esas': 591,\n",
              " 'rompio': 592,\n",
              " 'pedi': 593,\n",
              " 'banco': 594,\n",
              " 'vaya': 595,\n",
              " 'perfecto': 596,\n",
              " 'toca': 597,\n",
              " 'pie': 598,\n",
              " 'genial': 599,\n",
              " 'cambio': 600,\n",
              " 'falta': 601,\n",
              " 'anda': 602,\n",
              " 'corriendo': 603,\n",
              " 'recuerdo': 604,\n",
              " 'dicho': 605,\n",
              " 'enfadado': 606,\n",
              " 'quieras': 607,\n",
              " 'roto': 608,\n",
              " 'manzanas': 609,\n",
              " 'sera': 610,\n",
              " 'ruido': 611,\n",
              " 'conducir': 612,\n",
              " 'japones': 613,\n",
              " 'verlo': 614,\n",
              " 'gustaria': 615,\n",
              " 'llamar': 616,\n",
              " 'compro': 617,\n",
              " 'sol': 618,\n",
              " 'seria': 619,\n",
              " 'tokio': 620,\n",
              " 'cosa': 621,\n",
              " 'camara': 622,\n",
              " 'manera': 623,\n",
              " 'mantente': 624,\n",
              " 'vista': 625,\n",
              " 'vayas': 626,\n",
              " 'entra': 627,\n",
              " 'prisa': 628,\n",
              " 'comi': 629,\n",
              " 'pago': 630,\n",
              " 'cansada': 631,\n",
              " 'caliente': 632,\n",
              " 'atras': 633,\n",
              " 'fueron': 634,\n",
              " 'contento': 635,\n",
              " 'llega': 636,\n",
              " 'dejar': 637,\n",
              " 'irte': 638,\n",
              " 'cocina': 639,\n",
              " 'ayudarte': 640,\n",
              " 'pregunto': 641,\n",
              " 'medico': 642,\n",
              " 'mirando': 643,\n",
              " 'brazo': 644,\n",
              " 'matar': 645,\n",
              " 'viste': 646,\n",
              " 'tener': 647,\n",
              " 'hermanos': 648,\n",
              " 'puesto': 649,\n",
              " 'adonde': 650,\n",
              " 'empezar': 651,\n",
              " 'ningun': 652,\n",
              " 'timido': 653,\n",
              " 'abre': 654,\n",
              " 'dejalo': 655,\n",
              " 'pan': 656,\n",
              " 'escribe': 657,\n",
              " 'normal': 658,\n",
              " 'correcto': 659,\n",
              " 'mama': 660,\n",
              " 'problemas': 661,\n",
              " 'sed': 662,\n",
              " 'posible': 663,\n",
              " 'pasado': 664,\n",
              " 'habeis': 665,\n",
              " 'perder': 666,\n",
              " 'volvere': 667,\n",
              " 'turno': 668,\n",
              " 'vayamos': 669,\n",
              " 'vere': 670,\n",
              " 'sintio': 671,\n",
              " 'paga': 672,\n",
              " 'vacia': 673,\n",
              " 'cena': 674,\n",
              " 'ganas': 675,\n",
              " 'lloviendo': 676,\n",
              " 'todas': 677,\n",
              " 'dano': 678,\n",
              " 'quisiera': 679,\n",
              " 'esperanza': 680,\n",
              " 'paris': 681,\n",
              " 'aquel': 682,\n",
              " 'cualquier': 683,\n",
              " 'dar': 684,\n",
              " 'solia': 685,\n",
              " 'papel': 686,\n",
              " 'adentro': 687,\n",
              " 'luego': 688,\n",
              " 'ire': 689,\n",
              " 'sabemos': 690,\n",
              " 'quede': 691,\n",
              " 'salvo': 692,\n",
              " 'enferma': 693,\n",
              " 'rojo': 694,\n",
              " 'baja': 695,\n",
              " 'coge': 696,\n",
              " 'tuya': 697,\n",
              " 'llegado': 698,\n",
              " 'empieza': 699,\n",
              " 'pregunta': 700,\n",
              " 'mentiroso': 701,\n",
              " 'blanco': 702,\n",
              " 'irse': 703,\n",
              " 'guapa': 704,\n",
              " 'huele': 705,\n",
              " 'bus': 706,\n",
              " 'nosotras': 707,\n",
              " 'noticias': 708,\n",
              " 'nieve': 709,\n",
              " 'pego': 710,\n",
              " 'rio': 711,\n",
              " 'valiente': 712,\n",
              " 'disparo': 713,\n",
              " 'tonto': 714,\n",
              " 'limitate': 715,\n",
              " 'corazon': 716,\n",
              " 'haces': 717,\n",
              " 'viven': 718,\n",
              " 'apenas': 719,\n",
              " 'fiesta': 720,\n",
              " 'intento': 721,\n",
              " 'agradable': 722,\n",
              " 'abajo': 723,\n",
              " 'adelante': 724,\n",
              " 'espere': 725,\n",
              " 'vuelto': 726,\n",
              " 'sonrio': 727,\n",
              " 'raro': 728,\n",
              " 'caso': 729,\n",
              " 'quedar': 730,\n",
              " 'detesto': 731,\n",
              " 'hielo': 732,\n",
              " 'hago': 733,\n",
              " 'canta': 734,\n",
              " 'hicimos': 735,\n",
              " 'haga': 736,\n",
              " 'conocemos': 737,\n",
              " 'comprar': 738,\n",
              " 'unos': 739,\n",
              " 'dulce': 740,\n",
              " 'engano': 741,\n",
              " 'jefe': 742,\n",
              " 'pude': 743,\n",
              " 'tomo': 744,\n",
              " 'llevo': 745,\n",
              " 'empleo': 746,\n",
              " 'toco': 747,\n",
              " 'luz': 748,\n",
              " 'arma': 749,\n",
              " 'caballo': 750,\n",
              " 'dejes': 751,\n",
              " 'pescar': 752,\n",
              " 'tio': 753,\n",
              " 'menudo': 754,\n",
              " 'muchos': 755,\n",
              " 'verano': 756,\n",
              " 'llegar': 757,\n",
              " 'haber': 758,\n",
              " 'dientes': 759,\n",
              " 'consejo': 760,\n",
              " 'llover': 761,\n",
              " 'pidio': 762,\n",
              " 'foto': 763,\n",
              " 'torta': 764,\n",
              " 'nuestros': 765,\n",
              " 'hola': 766,\n",
              " 'vemos': 767,\n",
              " 'ponte': 768,\n",
              " 'intenta': 769,\n",
              " 'buenas': 770,\n",
              " 'terminado': 771,\n",
              " 'pasar': 772,\n",
              " 'sientate': 773,\n",
              " 'venid': 774,\n",
              " 'lee': 775,\n",
              " 'mando': 776,\n",
              " 'gratis': 777,\n",
              " 'hicieron': 778,\n",
              " 'miro': 779,\n",
              " 'debemos': 780,\n",
              " 'pero': 781,\n",
              " 'preparado': 782,\n",
              " 'nervioso': 783,\n",
              " 'vivir': 784,\n",
              " 'piensa': 785,\n",
              " 'colegio': 786,\n",
              " 'corto': 787,\n",
              " 'entro': 788,\n",
              " 'papa': 789,\n",
              " 'pajaro': 790,\n",
              " 'beso': 791,\n",
              " 'cuerda': 792,\n",
              " 'futbol': 793,\n",
              " 'caballos': 794,\n",
              " 'prefiero': 795,\n",
              " 'viendo': 796,\n",
              " 'escuchando': 797,\n",
              " 'japon': 798,\n",
              " 'eran': 799,\n",
              " 'adora': 800,\n",
              " 'escribio': 801,\n",
              " 'muerte': 802,\n",
              " 'enemigo': 803,\n",
              " 'confiar': 804,\n",
              " 'ventana': 805,\n",
              " 'fuego': 806,\n",
              " 'levanta': 807,\n",
              " 'preguntale': 808,\n",
              " 'hable': 809,\n",
              " 'lleno': 810,\n",
              " 'pajaros': 811,\n",
              " 'irnos': 812,\n",
              " 'adoro': 813,\n",
              " 'muriendo': 814,\n",
              " 'diez': 815,\n",
              " 'mire': 816,\n",
              " 'cualquiera': 817,\n",
              " 'agrada': 818,\n",
              " 'nueva': 819,\n",
              " 'contacto': 820,\n",
              " 'aire': 821,\n",
              " 'sopa': 822,\n",
              " 'atrapado': 823,\n",
              " 'cerro': 824,\n",
              " 'mayor': 825,\n",
              " 'pena': 826,\n",
              " 'paciencia': 827,\n",
              " 'ayudarme': 828,\n",
              " 'gustaba': 829,\n",
              " 'negro': 830,\n",
              " 'alta': 831,\n",
              " 'algunos': 832,\n",
              " 'peso': 833,\n",
              " 'dale': 834,\n",
              " 'nariz': 835,\n",
              " 'pienso': 836,\n",
              " 'respeto': 837,\n",
              " 'dan': 838,\n",
              " 'toques': 839,\n",
              " 'taza': 840,\n",
              " 'camion': 841,\n",
              " 'punto': 842,\n",
              " 'almuerzo': 843,\n",
              " 'dedo': 844,\n",
              " 'lapiz': 845,\n",
              " 'totalmente': 846,\n",
              " 'acerca': 847,\n",
              " 'corre': 848,\n",
              " 'quieto': 849,\n",
              " 'calvo': 850,\n",
              " 'debil': 851,\n",
              " 'cayo': 852,\n",
              " 'veia': 853,\n",
              " 'silencio': 854,\n",
              " 'arriba': 855,\n",
              " 'entonces': 856,\n",
              " 'cantando': 857,\n",
              " 'heroe': 858,\n",
              " 'soltero': 859,\n",
              " 'real': 860,\n",
              " 'ojo': 861,\n",
              " 'intentarlo': 862,\n",
              " 'verme': 863,\n",
              " 'vengo': 864,\n",
              " 'chicos': 865,\n",
              " 'azul': 866,\n",
              " 'gustas': 867,\n",
              " 'alguna': 868,\n",
              " 'necesitaba': 869,\n",
              " 'veces': 870,\n",
              " 'durmiendo': 871,\n",
              " 'monton': 872,\n",
              " 'grandes': 873,\n",
              " 'mios': 874,\n",
              " 'tarta': 875,\n",
              " 'descansar': 876,\n",
              " 'atencion': 877,\n",
              " 'claro': 878,\n",
              " 'robo': 879,\n",
              " 'encontrado': 880,\n",
              " 'escribir': 881,\n",
              " 'ley': 882,\n",
              " 'vendra': 883,\n",
              " 'treinta': 884,\n",
              " 'simplemente': 885,\n",
              " 'cinco': 886,\n",
              " 'gafas': 887,\n",
              " 'tele': 888,\n",
              " 'abierta': 889,\n",
              " 'peligroso': 890,\n",
              " 'mensaje': 891,\n",
              " 'cartas': 892,\n",
              " 'orgulloso': 893,\n",
              " 'abrir': 894,\n",
              " 'misma': 895,\n",
              " 'alegro': 896,\n",
              " 'continua': 897,\n",
              " 'ganado': 898,\n",
              " 'corrio': 899,\n",
              " 'ninguna': 900,\n",
              " 'calma': 901,\n",
              " 'ayudame': 902,\n",
              " 'mintio': 903,\n",
              " 'volar': 904,\n",
              " 'oscuro': 905,\n",
              " 'vimos': 906,\n",
              " 'hables': 907,\n",
              " 'asustado': 908,\n",
              " 'loca': 909,\n",
              " 'termina': 910,\n",
              " 'golf': 911,\n",
              " 'dudas': 912,\n",
              " 'confundido': 913,\n",
              " 'pierna': 914,\n",
              " 'abra': 915,\n",
              " 'necesitan': 916,\n",
              " 'gracioso': 917,\n",
              " 'vine': 918,\n",
              " 'primavera': 919,\n",
              " 'detras': 920,\n",
              " 'peor': 921,\n",
              " 'regalo': 922,\n",
              " 'espalda': 923,\n",
              " 'simple': 924,\n",
              " 'izquierda': 925,\n",
              " 'fuimos': 926,\n",
              " 'cuchillo': 927,\n",
              " 'traeme': 928,\n",
              " 'cambiado': 929,\n",
              " 'decision': 930,\n",
              " 'corbata': 931,\n",
              " 'crees': 932,\n",
              " 'abrio': 933,\n",
              " 'piano': 934,\n",
              " 'pasando': 935,\n",
              " 'paraguas': 936,\n",
              " 'piernas': 937,\n",
              " 'viajar': 938,\n",
              " 'completamente': 939,\n",
              " 'pelicula': 940,\n",
              " 'larga': 941,\n",
              " 'podrias': 942,\n",
              " 'creer': 943,\n",
              " 'caro': 944,\n",
              " 'abrigo': 945,\n",
              " 'hablas': 946,\n",
              " 'breve': 947,\n",
              " 'uso': 948,\n",
              " 'pagare': 949,\n",
              " 'estupendo': 950,\n",
              " 'toalla': 951,\n",
              " 'golpeo': 952,\n",
              " 'camina': 953,\n",
              " 'cruel': 954,\n",
              " 'mordio': 955,\n",
              " 'ocupados': 956,\n",
              " 'muneca': 957,\n",
              " 'deseo': 958,\n",
              " 'hermosa': 959,\n",
              " 'celoso': 960,\n",
              " 'saberlo': 961,\n",
              " 'canto': 962,\n",
              " 'bienvenido': 963,\n",
              " 'estudio': 964,\n",
              " 'culpable': 965,\n",
              " 'tenido': 966,\n",
              " 'bolso': 967,\n",
              " 'avion': 968,\n",
              " 'hambriento': 969,\n",
              " 'siente': 970,\n",
              " 'paz': 971,\n",
              " 'numero': 972,\n",
              " 'unas': 973,\n",
              " 'pelota': 974,\n",
              " 'riendo': 975,\n",
              " 'estara': 976,\n",
              " 'muertos': 977,\n",
              " 'trata': 978,\n",
              " 'viaje': 979,\n",
              " 'preocupado': 980,\n",
              " 'radio': 981,\n",
              " 'oficina': 982,\n",
              " 'lago': 983,\n",
              " 'entiende': 984,\n",
              " 'vives': 985,\n",
              " 'nacio': 986,\n",
              " 'siendo': 987,\n",
              " 'oportunidad': 988,\n",
              " 'escuche': 989,\n",
              " 'llamame': 990,\n",
              " 'entre': 991,\n",
              " 'gorda': 992,\n",
              " 'prueba': 993,\n",
              " 'profundo': 994,\n",
              " 'perfectamente': 995,\n",
              " 'llena': 996,\n",
              " 'pobre': 997,\n",
              " 'gane': 998,\n",
              " 'confia': 999,\n",
              " 'vosotras': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM3-sOuRoA1i"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0O-ZZDWolQ-",
        "outputId": "23f15294-8353-4477-a111-423e351e59ed"
      },
      "source": [
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "QWHzpwzGomYe",
        "outputId": "521a5244-38a1-4004-bc33-4e37e59d2267"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-3e50c60266be>\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    def initialize_hidden_state(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1Nlu7EhhyTVV",
        "outputId": "acbabe0d-f050-4f90-b9c3-5790195fa12f"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)# embed nowego inputu\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,  #1024 jednostki --> 1024 hidden state'y\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "'''\n",
        "dotyczy calla\n",
        ">>> inputs = tf.random.normal([32, 10, 8])\n",
        ">>> gru = tf.keras.layers.GRU(4)\n",
        ">>> output = gru(inputs)\n",
        ">>> print(output.shape)\n",
        "(32, 4)\n",
        ">>> gru = tf.keras.layers.GRU(4, return_sequences=True, return_state=True)\n",
        ">>> whole_sequence_output, final_state = gru(inputs)\n",
        ">>> print(whole_sequence_output.shape)\n",
        "(32, 10, 4)\n",
        ">>> print(final_state.shape)\n",
        "(32, 4)\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndotyczy calla\\n>>> inputs = tf.random.normal([32, 10, 8])\\n>>> gru = tf.keras.layers.GRU(4)\\n>>> output = gru(inputs)\\n>>> print(output.shape)\\n(32, 4)\\n>>> gru = tf.keras.layers.GRU(4, return_sequences=True, return_state=True)\\n>>> whole_sequence_output, final_state = gru(inputs)\\n>>> print(whole_sequence_output.shape)\\n(32, 10, 4)\\n>>> print(final_state.shape)\\n(32, 4)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYrqtrH82HG_",
        "outputId": "549632ea-4258-4982-88c7-32792eec71aa"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oWsVWBL2aaY"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    #query == hidden state (64*1024) # CHUJ # QUERY to nasz poprzedni stan Z DEKODERA\n",
        "    #pamiętajmy, że warstwa attention znajduje się pomiędzy enkoderem i dekoderem\n",
        "    #? dla naszego zapytania chcemy znaleźć odpowiednie wagi\n",
        "    print(query.shape)\n",
        "    print(values.shape) # values to kurwa cały output enkodera i porównujemy każdą edycję (i. e. słowo jeden, słowo dwa etc) z naszym query\n",
        "    # values shape == batch_size, max_len, hidden_size # whole_seq_output\n",
        "    # robimy to żeby dodawanie działało wzdłuż osi czasu\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values))) #score podobieństwa\n",
        "    \n",
        "    #attentioon_weights shape == batch, max_length, 1\n",
        "    attention_weights = tf.nn.softmax(score, axis=1) #na każde słowo jeden wynik\n",
        "\n",
        "\n",
        "    #context vector shape after sum == batch_size, hidden_size\n",
        "    context_vector = attention_weights * values\n",
        "    print(context_vector.shape)\n",
        "    print(context_vector)\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) #redukujemy wymiar czasu poprzez sumę żeby wyszedł finalny hidden input dla dekodera\n",
        "    print(context_vector.shape)\n",
        "    print(context_vector)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THV2dv5_6t_o"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGPon4z-6v8i",
        "outputId": "7b52312a-944a-4fc1-ea8e-f9bed684ce87"
      },
      "source": [
        "vocab_inp_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHXgXGxvJzC8"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    # attention as the first part of a decoder\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "   \n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        " # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "    print(x.shape)\n",
        "     # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # bez expand_dims concat nie zadziała, bo x jest dwuwymiarowe\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "    # print(output.shape) 64, 1, 1024\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    #  print(output.shape) 64 1024 only one is required for the next word\n",
        "    x = self.fc(output)\n",
        "    # x output shape == (batch_size, vocab)   \n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0m-XRfXeRdZ",
        "outputId": "e53bea84-ab6f-47c1-afa8-3a5cf6aec615"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-1.19145050e-04 -3.09461728e-04 -2.34913587e-05 ... -5.20101050e-04\n",
            "    1.68339291e-04  4.43701545e-04]\n",
            "  [-1.08849905e-04  2.34860527e-05 -1.14163803e-03 ... -3.57993209e-04\n",
            "   -7.04493199e-04  3.37160687e-04]\n",
            "  [-2.93444813e-04 -4.13618400e-04 -4.54432855e-04 ... -4.66872705e-04\n",
            "   -2.69289420e-04  2.60997447e-04]\n",
            "  ...\n",
            "  [-6.97062351e-04  1.26735563e-03 -1.53202331e-04 ... -8.82288208e-04\n",
            "   -5.41010173e-04 -7.95011467e-04]\n",
            "  [-7.04822654e-04  1.27379550e-03 -1.54258596e-04 ... -8.83791537e-04\n",
            "   -5.29915560e-04 -7.88998790e-04]\n",
            "  [-7.09088519e-04  1.27685943e-03 -1.54465233e-04 ... -8.84577166e-04\n",
            "   -5.23323775e-04 -7.84255681e-04]]\n",
            "\n",
            " [[-1.19260985e-04 -3.09762836e-04 -2.35142179e-05 ... -5.20607107e-04\n",
            "    1.68503102e-04  4.44133300e-04]\n",
            "  [ 4.29664178e-05 -9.24113992e-05 -6.09251612e-04 ... -4.52154258e-04\n",
            "    2.12182476e-05 -4.79535927e-04]\n",
            "  [ 3.41144856e-04  4.20737895e-04  2.24618598e-05 ...  1.26977829e-04\n",
            "   -2.03024421e-04 -4.13965492e-04]\n",
            "  ...\n",
            "  [-7.08185777e-04  1.26974611e-03 -1.50392792e-04 ... -8.81534826e-04\n",
            "   -5.37617481e-04 -8.07353761e-04]\n",
            "  [-7.12664274e-04  1.27527968e-03 -1.51837099e-04 ... -8.83914356e-04\n",
            "   -5.28067176e-04 -7.97229994e-04]\n",
            "  [-7.14613358e-04  1.27801730e-03 -1.52551336e-04 ... -8.85238696e-04\n",
            "   -5.22391812e-04 -7.89795187e-04]]\n",
            "\n",
            " [[-1.19289092e-04 -3.09835857e-04 -2.35197604e-05 ... -5.20729809e-04\n",
            "    1.68542814e-04  4.44237987e-04]\n",
            "  [ 4.90265433e-04 -4.75274981e-04 -2.28767050e-04 ... -5.01915696e-04\n",
            "   -3.36514058e-04 -2.35305750e-04]\n",
            "  [ 1.42471647e-04 -5.74929523e-04  1.78896546e-04 ... -1.20019249e-04\n",
            "   -6.14719873e-04 -1.19798540e-04]\n",
            "  ...\n",
            "  [-6.81040285e-04  1.25998689e-03 -1.60254509e-04 ... -8.69818963e-04\n",
            "   -5.64050279e-04 -8.24088522e-04]\n",
            "  [-6.96987787e-04  1.26929639e-03 -1.58700524e-04 ... -8.76719307e-04\n",
            "   -5.44704089e-04 -8.08529556e-04]\n",
            "  [-7.05727027e-04  1.27444603e-03 -1.57176430e-04 ... -8.80697567e-04\n",
            "   -5.32663544e-04 -7.97185290e-04]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.18728291e-04 -3.08379240e-04 -2.34091895e-05 ... -5.18281769e-04\n",
            "    1.67750462e-04  4.42149525e-04]\n",
            "  [-4.46360646e-04 -2.22165487e-04 -9.85145380e-05 ... -8.14899162e-04\n",
            "    2.65085255e-04  2.50791258e-04]\n",
            "  [-9.65534477e-04 -5.58163913e-04 -3.76278418e-04 ... -6.92245609e-04\n",
            "   -5.84937152e-05 -8.83239845e-05]\n",
            "  ...\n",
            "  [-6.78647193e-04  1.24923000e-03 -1.50142747e-04 ... -8.56674626e-04\n",
            "   -5.52514219e-04 -8.18824978e-04]\n",
            "  [-6.92931528e-04  1.26151892e-03 -1.52719338e-04 ... -8.67368188e-04\n",
            "   -5.36384818e-04 -8.04345647e-04]\n",
            "  [-7.01185083e-04  1.26781885e-03 -1.53569286e-04 ... -8.73685349e-04\n",
            "   -5.26453019e-04 -7.93456216e-04]]\n",
            "\n",
            " [[-1.19577475e-04 -3.10584874e-04 -2.35766183e-05 ... -5.21988724e-04\n",
            "    1.68950268e-04  4.45311918e-04]\n",
            "  [-1.42358709e-04 -4.96454013e-04 -2.45073024e-04 ... -2.73629616e-04\n",
            "    3.14652389e-05 -2.53100443e-04]\n",
            "  [ 8.65653419e-05  1.04322120e-04 -1.35828668e-04 ...  2.43602160e-04\n",
            "    2.41438116e-04 -2.49176781e-04]\n",
            "  ...\n",
            "  [-7.13764573e-04  1.27733685e-03 -1.53997884e-04 ... -8.83305329e-04\n",
            "   -5.31086058e-04 -7.99209054e-04]\n",
            "  [-7.16453593e-04  1.28036656e-03 -1.54342197e-04 ... -8.85676418e-04\n",
            "   -5.24926174e-04 -7.91628496e-04]\n",
            "  [-7.17533403e-04  1.28194154e-03 -1.54368521e-04 ... -8.87077302e-04\n",
            "   -5.21392678e-04 -7.86519144e-04]]\n",
            "\n",
            " [[-1.19083386e-04 -3.09301569e-04 -2.34792024e-05 ... -5.19831898e-04\n",
            "    1.68252169e-04  4.43471916e-04]\n",
            "  [-7.04771432e-04 -2.04675380e-04  2.07015240e-04 ... -1.46591090e-04\n",
            "    5.03304764e-04 -1.51017273e-04]\n",
            "  [-3.79681645e-04 -5.75026097e-05 -6.45303866e-04 ... -3.53237789e-04\n",
            "    1.79349503e-04  3.02282395e-04]\n",
            "  ...\n",
            "  [-6.96271483e-04  1.26619078e-03 -1.57154122e-04 ... -8.76055914e-04\n",
            "   -5.41649293e-04 -8.05391348e-04]\n",
            "  [-7.05004903e-04  1.27214810e-03 -1.56790731e-04 ... -8.80290812e-04\n",
            "   -5.30436868e-04 -7.95230852e-04]\n",
            "  [-7.09651795e-04  1.27511262e-03 -1.56028269e-04 ... -8.82669934e-04\n",
            "   -5.23718074e-04 -7.87833240e-04]]], shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.00419089  0.01051173 -0.00221851 ... -0.00987609 -0.00856993\n",
            "  -0.00561426]\n",
            " [-0.00405953  0.01286162 -0.00112016 ... -0.00869061 -0.0055965\n",
            "  -0.00844128]\n",
            " [-0.00318613  0.00871603 -0.00086711 ... -0.01039214 -0.00934965\n",
            "  -0.00644119]\n",
            " ...\n",
            " [-0.00636098  0.0086371   0.00117099 ... -0.00978098 -0.0058503\n",
            "  -0.00761846]\n",
            " [-0.00523784  0.01312778 -0.00086952 ... -0.00961245 -0.0059623\n",
            "  -0.00913543]\n",
            " [-0.00472449  0.01231738 -0.00041179 ... -0.0091554  -0.00550121\n",
            "  -0.00720115]], shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk_t7d2YeRzD"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) #jeśli mamy 0 w teście to fałsz\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask  #ignorujemy wszystkie straty poza niezerowymi\n",
        "\n",
        "  return tf.reduce_mean(loss_) # średnia w batchu\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcUtSrSFhRLv"
      },
      "source": [
        "#checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dihrV8eicmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL9YYkXDidSo"
      },
      "source": [
        "Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
        "\n",
        "The decoder returns the predictions and the decoder hidden state.\n",
        "\n",
        "The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
        "\n",
        "Use teacher forcing to decide the next input to the decoder.\n",
        "\n",
        "Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
        "\n",
        "\n",
        "The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87VhO9qHindY"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden # first hidden state of the decoder\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)  # 64 tokeny startowe w batchu, rozmiar (64, 1) żeby pasowało\n",
        "\n",
        "    #Teacher forcing - we use the proper word target as the nexct input\n",
        "\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # pass full enc_output to the decoder\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # use teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1) #używamy poprzedniego prawidłowego słowa jako jedyny input dekodera oprócz hidden state'u\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables)) #iterable\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn6veiQxkuNF",
        "outputId": "89bfe3e8-de26-4d49-d13a-676453452305"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    \n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "   # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_1:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_1:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_2:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_2:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_3:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_3:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_4:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_4:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_5:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_5:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_6:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_6:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_7:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_7:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_8:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_8:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_9:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_9:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_1:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_1:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_2:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_2:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_3:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_3:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_4:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_4:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_5:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_5:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_6:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_6:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_7:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_7:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_8:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_8:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "(64, 1024)\n",
            "(64, 16, 1024)\n",
            "(64, 16, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/mul_9:0\", shape=(64, 16, 1024), dtype=float32)\n",
            "(64, 1024)\n",
            "Tensor(\"decoder_1/bahdanau_attention_3/Sum_9:0\", shape=(64, 1024), dtype=float32)\n",
            "(64, 1, 256)\n",
            "(64, 1, 1024)\n",
            "(64, 1024)\n",
            "Epoch 1 Batch 0 Loss 4.4934\n",
            "Epoch 1 Batch 100 Loss 2.0575\n",
            "Epoch 1 Batch 200 Loss 1.8347\n",
            "Epoch 1 Batch 300 Loss 1.6653\n",
            "Epoch 1 Loss 2.0577\n",
            "Time taken for 1 epoch 1304.3415927886963 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4782\n",
            "Epoch 2 Batch 100 Loss 1.6200\n",
            "Epoch 2 Batch 200 Loss 1.4995\n",
            "Epoch 2 Batch 300 Loss 1.3770\n",
            "Epoch 2 Loss 1.4469\n",
            "Time taken for 1 epoch 1281.2536725997925 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0521\n",
            "Epoch 3 Batch 100 Loss 1.1873\n",
            "Epoch 3 Batch 200 Loss 1.0631\n",
            "Epoch 3 Batch 300 Loss 0.9639\n",
            "Epoch 3 Loss 1.0306\n",
            "Time taken for 1 epoch 1281.7761361598969 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7857\n",
            "Epoch 4 Batch 100 Loss 0.6783\n",
            "Epoch 4 Batch 200 Loss 0.6631\n",
            "Epoch 4 Batch 300 Loss 0.6555\n",
            "Epoch 4 Loss 0.6998\n",
            "Time taken for 1 epoch 1286.476179599762 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4980\n",
            "Epoch 5 Batch 100 Loss 0.5496\n",
            "Epoch 5 Batch 200 Loss 0.4925\n",
            "Epoch 5 Batch 300 Loss 0.4074\n",
            "Epoch 5 Loss 0.4769\n",
            "Time taken for 1 epoch 1283.8991420269012 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2457\n",
            "Epoch 6 Batch 100 Loss 0.3394\n",
            "Epoch 6 Batch 200 Loss 0.3055\n",
            "Epoch 6 Batch 300 Loss 0.3204\n",
            "Epoch 6 Loss 0.3300\n",
            "Time taken for 1 epoch 1285.6540179252625 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2107\n",
            "Epoch 7 Batch 100 Loss 0.2320\n",
            "Epoch 7 Batch 200 Loss 0.2179\n",
            "Epoch 7 Batch 300 Loss 0.3197\n",
            "Epoch 7 Loss 0.2361\n",
            "Time taken for 1 epoch 1284.4786956310272 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1690\n",
            "Epoch 8 Batch 100 Loss 0.1434\n",
            "Epoch 8 Batch 200 Loss 0.1680\n",
            "Epoch 8 Batch 300 Loss 0.2206\n",
            "Epoch 8 Loss 0.1742\n",
            "Time taken for 1 epoch 1284.1698307991028 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1073\n",
            "Epoch 9 Batch 100 Loss 0.1421\n",
            "Epoch 9 Batch 200 Loss 0.1271\n",
            "Epoch 9 Batch 300 Loss 0.1488\n",
            "Epoch 9 Loss 0.1359\n",
            "Time taken for 1 epoch 1284.0252459049225 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0573\n",
            "Epoch 10 Batch 100 Loss 0.1377\n",
            "Epoch 10 Batch 200 Loss 0.0764\n",
            "Epoch 10 Batch 300 Loss 0.1213\n",
            "Epoch 10 Loss 0.1087\n",
            "Time taken for 1 epoch 1283.3366503715515 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GujjuymmAA0"
      },
      "source": [
        "\n",
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        " \n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ') if i!= '']\n",
        "\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n",
        "#small function for plotting the weights\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize' : 14}\n",
        "  ax.set_xticklabels([''] + sentence, fontdict = fontdict, rotation = 90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict = fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nr_J6YxrvhdM",
        "outputId": "aee571fd-fe48-4766-8f7e-497e42264194"
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "translate(u'hace mucho frio aqui.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-9.6210465e-07  6.2916019e-09 -6.3378172e-07 ... -3.9125649e-07\n",
            "   -1.4924718e-06  2.4322966e-07]\n",
            "  [-1.5289286e-05  3.3064836e-07 -6.0511047e-06 ... -3.2141074e-07\n",
            "   -1.9807909e-05  6.7256315e-06]\n",
            "  [-1.4264396e-03  2.2601102e-05 -8.9595234e-04 ... -2.2888156e-05\n",
            "    7.9119101e-04  2.9270656e-03]\n",
            "  ...\n",
            "  [-4.8266254e-02  5.5627839e-04 -5.2366168e-03 ... -7.6523318e-04\n",
            "    9.2480816e-02  7.3146850e-02]\n",
            "  [-5.2094996e-02  5.5120222e-04 -5.2613905e-03 ... -7.7673432e-04\n",
            "    9.1919430e-02  7.2702937e-02]\n",
            "  [-5.5653282e-02  5.4680416e-04 -5.2892133e-03 ... -7.8898412e-04\n",
            "    9.1465883e-02  7.2343975e-02]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.40702066  0.00606882 -0.0571375  ... -0.00783724  0.8754614\n",
            "   0.79081166]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-5.0754985e-03  3.3190794e-05 -3.3434597e-03 ... -2.0640390e-03\n",
            "   -7.8734038e-03  1.2831365e-03]\n",
            "  [-2.2424822e-01  4.8496248e-03 -8.8751651e-02 ... -4.7141365e-03\n",
            "   -2.9052293e-01  9.8644942e-02]\n",
            "  [-8.9421332e-02  1.4168288e-03 -5.6165893e-02 ... -1.4348237e-03\n",
            "    4.9598567e-02  1.8349330e-01]\n",
            "  ...\n",
            "  [-4.6478010e-05  5.3566851e-07 -5.0426020e-06 ... -7.3688159e-07\n",
            "    8.9054432e-05  7.0436792e-05]\n",
            "  [-5.0162605e-05  5.3075615e-07 -5.0662265e-06 ... -7.4792246e-07\n",
            "    8.8509812e-05  7.0006128e-05]\n",
            "  [-5.3572498e-05  5.2636011e-07 -5.0914582e-06 ... -7.5948532e-07\n",
            "    8.8046130e-05  6.9639158e-05]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.33489034  0.00665182 -0.16093826 ... -0.00866904 -0.23946501\n",
            "   0.3283977 ]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-1.9268240e-03  1.2600302e-05 -1.2692859e-03 ... -7.8357628e-04\n",
            "   -2.9889997e-03  4.8712033e-04]\n",
            "  [-6.0085263e-02  1.2994127e-03 -2.3780193e-02 ... -1.2631097e-03\n",
            "   -7.7842966e-02  2.6431013e-02]\n",
            "  [-1.7682426e-01  2.8016772e-03 -1.1106402e-01 ... -2.8372607e-03\n",
            "    9.8077595e-02  3.6284479e-01]\n",
            "  ...\n",
            "  [-3.7343978e-04  4.3039690e-06 -4.0516112e-05 ... -5.9206686e-06\n",
            "    7.1553123e-04  5.6594290e-04]\n",
            "  [-4.0550940e-04  4.2905790e-06 -4.0954859e-05 ... -6.0461293e-06\n",
            "    7.1550434e-04  5.6592241e-04]\n",
            "  [-4.3468922e-04  4.2709053e-06 -4.1312280e-05 ... -6.1624919e-06\n",
            "    7.1440951e-04  5.6505471e-04]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.33668     0.0062427  -0.21274275 ... -0.00764138  0.0720657\n",
            "   0.6616653 ]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-2.4679780e-04  1.6139134e-06 -1.6257683e-04 ... -1.0036459e-04\n",
            "   -3.8284686e-04  6.2392945e-05]\n",
            "  [-1.6974141e-03  3.6708527e-05 -6.7179260e-04 ... -3.5682966e-05\n",
            "   -2.1990708e-03  7.4667850e-04]\n",
            "  [-4.6631873e-02  7.3885481e-04 -2.9289665e-02 ... -7.4823888e-04\n",
            "    2.5864903e-02  9.5688984e-02]\n",
            "  ...\n",
            "  [-9.4467323e-05  1.0887551e-06 -1.0249172e-05 ... -1.4977240e-06\n",
            "    1.8100461e-04  1.4316394e-04]\n",
            "  [-1.0123643e-04  1.0711537e-06 -1.0224483e-05 ... -1.5094312e-06\n",
            "    1.7862744e-04  1.4128393e-04]\n",
            "  [-1.0732180e-04  1.0544572e-06 -1.0199719e-05 ... -1.5214771e-06\n",
            "    1.7638283e-04  1.3950813e-04]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.2946179   0.00618026 -0.2130476  ... -0.0078176   0.12513341\n",
            "   0.78638023]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-2.09980001e-07  1.37314649e-09 -1.38323301e-07 ... -8.53919957e-08\n",
            "   -3.25732998e-07  5.30850386e-08]\n",
            "  [-4.84750717e-06  1.04832900e-07 -1.91851814e-06 ... -1.01904085e-07\n",
            "   -6.28014777e-06  2.13237854e-06]\n",
            "  [-4.98593610e-04  7.89992464e-06 -3.13168595e-04 ... -8.00026010e-06\n",
            "    2.76550651e-04  1.02311803e-03]\n",
            "  ...\n",
            "  [-3.39607330e-04  3.91404365e-06 -3.68454821e-05 ... -5.38427548e-06\n",
            "    6.50706410e-04  5.14670275e-04]\n",
            "  [-3.61039100e-04  3.82005146e-06 -3.64635343e-05 ... -5.38307859e-06\n",
            "    6.37038320e-04  5.03860356e-04]\n",
            "  [-3.79894307e-04  3.73253465e-06 -3.61046441e-05 ... -5.38567656e-06\n",
            "    6.24354405e-04  4.93826519e-04]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.28315598  0.00619658 -0.0479669  ... -0.00722475 -0.15465456\n",
            "   0.79261047]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-1.7088817e-09  1.1175088e-11 -1.1257175e-09 ... -6.9494627e-10\n",
            "   -2.6509153e-09  4.3202233e-10]\n",
            "  [-7.0214192e-08  1.5184624e-09 -2.7788962e-08 ... -1.4760397e-09\n",
            "   -9.0965415e-08  3.0886646e-08]\n",
            "  [-1.2048323e-05  1.9089865e-07 -7.5675994e-06 ... -1.9332322e-07\n",
            "    6.6827401e-06  2.4723257e-05]\n",
            "  ...\n",
            "  [-1.2677544e-03  1.4611126e-05 -1.3754419e-04 ... -2.0099502e-05\n",
            "    2.4290874e-03  1.9212645e-03]\n",
            "  [-1.3491949e-03  1.4275445e-05 -1.3626339e-04 ... -2.0116442e-05\n",
            "    2.3805979e-03  1.8829148e-03]\n",
            "  [-1.4250912e-03  1.4001795e-05 -1.3543875e-04 ... -2.0203199e-05\n",
            "    2.3421301e-03  1.8524830e-03]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.28433782  0.00616602 -0.04340107 ... -0.00725221  0.15725425\n",
            "   0.79095   ]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-1.4344820e-08  9.3806740e-11 -9.4495807e-09 ... -5.8335692e-09\n",
            "   -2.2252507e-08  3.6265135e-09]\n",
            "  [-3.3886857e-07  7.3284214e-09 -1.3411542e-07 ... -7.1236808e-09\n",
            "   -4.3901838e-07  1.4906550e-07]\n",
            "  [-3.5498029e-05  5.6244556e-07 -2.2296454e-05 ... -5.6958913e-07\n",
            "    1.9689389e-05  7.2842246e-05]\n",
            "  ...\n",
            "  [-1.8407822e-03  2.1215388e-05 -1.9971450e-04 ... -2.9184523e-05\n",
            "    3.5270404e-03  2.7896804e-03]\n",
            "  [-1.9873052e-03  2.1027108e-05 -2.0071004e-04 ... -2.9630643e-05\n",
            "    3.5065168e-03  2.7734514e-03]\n",
            "  [-2.1267866e-03  2.0896086e-05 -2.0212695e-04 ... -3.0150977e-05\n",
            "    3.4953631e-03  2.7646204e-03]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.28563407  0.00614827 -0.04558383 ... -0.00729007  0.37269187\n",
            "   0.790764  ]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "Input: <start> hace mucho frio aqui .  <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dTG_p0HUvngw",
        "outputId": "22c5b627-1da8-4a71-f871-e0eb2f2f25ec"
      },
      "source": [
        "translate('esta')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-7.3411616e-07  4.8006905e-09 -4.8359544e-07 ... -2.9854104e-07\n",
            "   -1.1388031e-06  1.8559189e-07]\n",
            "  [-1.4168079e-05 -7.7806374e-07  2.7188264e-07 ... -7.5522371e-07\n",
            "   -1.0199008e-05 -1.7332964e-05]\n",
            "  [-8.9980569e-03 -1.1991381e-04  4.6399643e-04 ... -6.7189854e-04\n",
            "    5.4800916e-03  1.1404973e-02]\n",
            "  ...\n",
            "  [-4.8989967e-02  2.4937207e-03 -4.3055002e-02 ... -3.5703199e-03\n",
            "    9.4241537e-02  5.4126870e-02]\n",
            "  [-5.1547475e-02  2.4885584e-03 -4.3691102e-02 ... -3.7202835e-03\n",
            "    9.4774522e-02  5.4432888e-02]\n",
            "  [-5.4034896e-02  2.4796696e-03 -4.4234551e-02 ... -3.8667805e-03\n",
            "    9.5160358e-02  5.4654520e-02]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.46855104  0.02532005 -0.39978075 ... -0.03461288  0.9240943\n",
            "   0.57326   ]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-1.8018482e-03  1.1783034e-05 -1.1869587e-03 ... -7.3275273e-04\n",
            "   -2.7951302e-03  4.5552521e-04]\n",
            "  [-1.7652649e-01 -9.6942475e-03  3.3875084e-03 ... -9.4096726e-03\n",
            "   -1.2707405e-01 -2.1595922e-01]\n",
            "  [-2.1303789e-01 -2.8390782e-03  1.0985575e-02 ... -1.5907861e-02\n",
            "    1.2974659e-01  2.7002403e-01]\n",
            "  ...\n",
            "  [-3.8763796e-05  1.9731813e-06 -3.4067696e-05 ... -2.8250508e-06\n",
            "    7.4569543e-05  4.2828422e-05]\n",
            "  [-4.0260074e-05  1.9436363e-06 -3.4124019e-05 ... -2.9056494e-06\n",
            "    7.4021649e-05  4.2513664e-05]\n",
            "  [-4.1756295e-05  1.9162028e-06 -3.4182929e-05 ... -2.9881141e-06\n",
            "    7.3536627e-05  4.2235122e-05]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.4015073  -0.01241535  0.01285316 ... -0.02678802  0.00503677\n",
            "   0.06835284]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-5.7004829e-04  3.7277825e-06 -3.7551651e-04 ... -2.3181998e-04\n",
            "   -8.8429154e-04  1.4411389e-04]\n",
            "  [-7.9936031e-03 -4.3898207e-04  1.5339567e-04 ... -4.2609576e-04\n",
            "   -5.7542608e-03 -9.7792251e-03]\n",
            "  [-3.3904341e-01 -4.5183073e-03  1.7483210e-02 ... -2.5316883e-02\n",
            "    2.0648779e-01  4.2973509e-01]\n",
            "  ...\n",
            "  [-1.6420988e-04  8.3587238e-06 -1.4431642e-04 ... -1.1967385e-05\n",
            "    3.1588899e-04  1.8142832e-04]\n",
            "  [-1.6712878e-04  8.0684795e-06 -1.4165661e-04 ... -1.2062015e-05\n",
            "    3.0728083e-04  1.7648394e-04]\n",
            "  [-1.7009793e-04  7.8058201e-06 -1.3924716e-04 ... -1.2172344e-05\n",
            "    2.9955790e-04  1.7204846e-04]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.4134893  -0.00409594  0.01471491 ... -0.03076992  0.23497623\n",
            "   0.5101439 ]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-2.4490492e-04  1.6015350e-06 -1.6132991e-04 ... -9.9594814e-05\n",
            "   -3.7991052e-04  6.1914405e-05]\n",
            "  [-8.7504048e-04 -4.8054309e-05  1.6791853e-05 ... -4.6643676e-05\n",
            "   -6.2990503e-04 -1.0705083e-03]\n",
            "  [-1.6326508e-01 -2.1757740e-03  8.4189745e-03 ... -1.2191250e-02\n",
            "    9.9433422e-02  2.0693733e-01]\n",
            "  ...\n",
            "  [-2.7038349e-04  1.3763245e-05 -2.3762745e-04 ... -1.9705167e-05\n",
            "    5.2013411e-04  2.9873487e-04]\n",
            "  [-2.7118201e-04  1.3091858e-05 -2.2985104e-04 ... -1.9571742e-05\n",
            "    4.9859169e-04  2.8636161e-04]\n",
            "  [-2.7247076e-04  1.2503726e-05 -2.2305256e-04 ... -1.9498228e-05\n",
            "    4.7984577e-04  2.7559523e-04]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.41637173  0.00229861 -0.00600054 ... -0.0306948   0.24684505\n",
            "   0.55122495]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "(1, 1024)\n",
            "(1, 16, 1024)\n",
            "(1, 16, 1024)\n",
            "tf.Tensor(\n",
            "[[[-1.00505497e-06  6.57247234e-09 -6.62075081e-07 ... -4.08722997e-07\n",
            "   -1.55909891e-06  2.54087951e-07]\n",
            "  [-2.40310474e-05 -1.31970512e-06  4.61151046e-07 ... -1.28096519e-06\n",
            "   -1.72989457e-05 -2.93991361e-05]\n",
            "  [-5.84888365e-03 -7.79459369e-05  3.01605265e-04 ... -4.36745002e-04\n",
            "    3.56214913e-03  7.41341896e-03]\n",
            "  ...\n",
            "  [-6.53491635e-03  3.32644762e-04 -5.74323349e-03 ... -4.76255460e-04\n",
            "    1.25711560e-02  7.22014252e-03]\n",
            "  [-6.56419434e-03  3.16899735e-04 -5.56374295e-03 ... -4.73750901e-04\n",
            "    1.20688435e-02  6.93163043e-03]\n",
            "  [-6.58863224e-03  3.02353350e-04 -5.39364759e-03 ... -4.71487816e-04\n",
            "    1.16031794e-02  6.66418485e-03]]], shape=(1, 16, 1024), dtype=float32)\n",
            "(1, 1024)\n",
            "tf.Tensor(\n",
            "[[-0.422659    0.0188565  -0.17360848 ... -0.03106345  0.53859967\n",
            "   0.5733643 ]], shape=(1, 1024), dtype=float32)\n",
            "(1, 1, 256)\n",
            "(1, 1, 1024)\n",
            "(1, 1024)\n",
            "Input: <start> esta <end>\n",
            "Predicted translation: he s right . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "P1my512Pvozv",
        "outputId": "c8e09f4f-27c6-481c-b9da-5ee733a76e44"
      },
      "source": [
        "translate(u'¿todavia estan en casa?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-196315b2ba9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'¿todavia estan en casa?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-cb0b6a0e4843>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-cb0b6a0e4843>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m      9\u001b[0m                                                          \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-cb0b6a0e4843>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m      9\u001b[0m                                                          \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUALhZZ1vqG4"
      },
      "source": [
        "translate(u'trata de averiguarlo.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}