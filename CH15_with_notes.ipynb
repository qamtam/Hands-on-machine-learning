{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CH15_with_notes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHZ7yabsz5XOwh9m2SPdR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qamtam/Hands-on-machine-learning/blob/main/CH15_with_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkCEN9OIxdOw"
      },
      "source": [
        "# RNNs\n",
        "# Generally they can take on sequences of arbitrary length rather than fixed sized inputs\n",
        "\n",
        "# Troubles of RNNs\n",
        "# Unstable gradients - curable with recurrent dropout and recurrent layer normalization\n",
        "# limited short term memory\n",
        "\n",
        "\n",
        "# types of networks\n",
        "# seq-to-seq (sequence produce a sequence later) like stock prices from N-1 days to today produce stock prices from N to tommorow\n",
        "# seq-to-vec like words of a review to sentiment of said review (-1 or 1)\n",
        "# vec-to-sec like image into sequence of labels that describe that image\n",
        "# sec-to-vec (encoder) --> vec-to-sec (decoder) like a translator that takes a sequence of words from one language, encodes it into a \"universal representation\" in a vector and then decoders tries to decode it into a foreign language\n",
        "\n",
        "# types of forecasting in time series\n",
        "# prediction of future values (stonk)\n",
        "# inputation of previous missing values (\"postdiction\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q06TE-RW7XiI"
      },
      "source": [
        "#common shit per usual\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "np.set_printoptions(threshold=np.inf) # print pretty pony tables\n",
        "np.set_printoptions(linewidth=2000)\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"rnn\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh2nqlGa7i79"
      },
      "source": [
        "def generate_time_series(batch_size, n_steps):\n",
        "  freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
        " # print(\"freq1: \", freq1, \"\\n freq2 \", freq2,  \"\\n offsets1\", offsets1, \"\\n offsets2\" ,offsets2)\n",
        "  time = np.linspace(0, 1, n_steps)\n",
        "  wave1 = 0.5 * np.sin((time - offsets1) * (freq1 * 30 + 10)) # amplitude offset (przesunięcie) frequency #okres\n",
        "  wave2 = 0.5 * np.sin((time - offsets2) * (freq1 * 20 + 20)) \n",
        "  noise = 0.1 * (np.random.rand(batch_size, n_steps)-0.5)\n",
        "  # plt.plot(time, wave1[0])\n",
        "  series = wave1 + wave2 + noise\n",
        "  return series[..., np.newaxis].astype(np.float32)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uImxfiY8KcZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbd310a3-3820-484f-f076-c71f78b3af32"
      },
      "source": [
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 1)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
        "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]\n",
        "#metrics\n",
        "#naive prediction: just yeet the last known value of time series as your prediction\n",
        "#after all, your stonks don't move that much day to day\n",
        "#surprisingly hard to outperform\n",
        "\n",
        "np.mean(keras.losses.mean_squared_error(y_valid, X_valid[:,-1]))\n",
        "# about 0.07"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07822794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAlV1UObCzFd",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ece2883-0b4f-4c62-dbf2-9ee1b521926d"
      },
      "source": [
        "#metrics\n",
        "#simple fully connected network and compare with that\n",
        "#about 0.04\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.Flatten(input_shape=[50,1]),\n",
        "                                 keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2307 - val_loss: 0.1139\n",
            "Epoch 2/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0749 - val_loss: 0.0516\n",
            "Epoch 3/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0413 - val_loss: 0.0349\n",
            "Epoch 4/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0307 - val_loss: 0.0273\n",
            "Epoch 5/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0246 - val_loss: 0.0219\n",
            "Epoch 6/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0201 - val_loss: 0.0180\n",
            "Epoch 7/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0151\n",
            "Epoch 8/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0129\n",
            "Epoch 9/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0113\n",
            "Epoch 10/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0101\n",
            "Epoch 11/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0092\n",
            "Epoch 12/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0092 - val_loss: 0.0087\n",
            "Epoch 13/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0081\n",
            "Epoch 14/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0077\n",
            "Epoch 15/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 16/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 17/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 18/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0066\n",
            "Epoch 19/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0064\n",
            "Epoch 20/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0063\n",
            "Epoch 21/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0060\n",
            "Epoch 22/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0059\n",
            "Epoch 23/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0057\n",
            "Epoch 24/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0055\n",
            "Epoch 25/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0055\n",
            "Epoch 26/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0054 - val_loss: 0.0053\n",
            "Epoch 27/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0053 - val_loss: 0.0052\n",
            "Epoch 28/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0052 - val_loss: 0.0051\n",
            "Epoch 29/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0051 - val_loss: 0.0050\n",
            "Epoch 30/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0050 - val_loss: 0.0049\n",
            "Epoch 31/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 32/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 33/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0047 - val_loss: 0.0047\n",
            "Epoch 34/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 35/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
            "Epoch 36/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
            "Epoch 37/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0045 - val_loss: 0.0044\n",
            "Epoch 38/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 39/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0044 - val_loss: 0.0044\n",
            "Epoch 40/40\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.0043 - val_loss: 0.0043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb650162f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYAj03OlDOd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3aae596b-434b-4406-f8f6-6e6e75507f67"
      },
      "source": [
        "# your first RNN\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(1, input_shape=[None,1])\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.1041 - val_loss: 0.0848\n",
            "Epoch 2/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0741 - val_loss: 0.0614\n",
            "Epoch 3/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0556 - val_loss: 0.0482\n",
            "Epoch 4/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0463 - val_loss: 0.0424\n",
            "Epoch 5/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0421 - val_loss: 0.0395\n",
            "Epoch 6/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0398 - val_loss: 0.0376\n",
            "Epoch 7/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0380 - val_loss: 0.0360\n",
            "Epoch 8/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0366 - val_loss: 0.0348\n",
            "Epoch 9/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0355 - val_loss: 0.0339\n",
            "Epoch 10/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0347 - val_loss: 0.0333\n",
            "Epoch 11/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0342 - val_loss: 0.0330\n",
            "Epoch 12/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0339 - val_loss: 0.0327\n",
            "Epoch 13/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0337 - val_loss: 0.0326\n",
            "Epoch 14/40\n",
            "219/219 [==============================] - 10s 44ms/step - loss: 0.0337 - val_loss: 0.0325\n",
            "Epoch 15/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 16/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 17/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 18/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 19/40\n",
            "219/219 [==============================] - 11s 48ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 20/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 21/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 22/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 23/40\n",
            "219/219 [==============================] - 11s 48ms/step - loss: 0.0336 - val_loss: 0.0326\n",
            "Epoch 24/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0326\n",
            "Epoch 25/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 26/40\n",
            "219/219 [==============================] - 10s 45ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 27/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 28/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 29/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 30/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0326\n",
            "Epoch 31/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 32/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0326\n",
            "Epoch 33/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0326\n",
            "Epoch 34/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 35/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 36/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 37/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 38/40\n",
            "219/219 [==============================] - 10s 46ms/step - loss: 0.0336 - val_loss: 0.0326\n",
            "Epoch 39/40\n",
            "219/219 [==============================] - 10s 47ms/step - loss: 0.0336 - val_loss: 0.0325\n",
            "Epoch 40/40\n",
            "219/219 [==============================] - 10s 48ms/step - loss: 0.0336 - val_loss: 0.0325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb5fdf34780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O6VKIfmFgnF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b72121dd-0089-4efb-dbe9-7d6dfd12c82b"
      },
      "source": [
        "#deep RNN is just a vertical stack of RNNs\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences=True, batch_input_shape=[50, None,1]),\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences=True),\n",
        "                                 keras.layers.SimpleRNN(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "for layer in model.layers:\n",
        "    print(layer.output_shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=1, batch_size=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, None, 20)\n",
            "(50, None, 20)\n",
            "(50, 1)\n",
            "140/140 [==============================] - 12s 88ms/step - loss: 0.0438 - val_loss: 0.0118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb5fcbf5e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zotEb-7RJEmm"
      },
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5ftThB6L3tQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "4c12224f-47e0-4deb-82a2-a74458a8dcdf"
      },
      "source": [
        "#deep RNN is just a vertical stack of RNNs\n",
        "#deep RNN is just a vertical stack of RNNs\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "                                 keras.layers.SimpleRNN(20),\n",
        "                                 keras.layers.Dense(1)\n",
        "                                 \n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)\n",
        "for layer in model.layers:\n",
        "    print(layer.output_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 21s 97ms/step - loss: 0.1375 - val_loss: 0.0120\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 21s 95ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0054 - val_loss: 0.0054\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 20s 93ms/step - loss: 0.0044 - val_loss: 0.0043\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 20s 94ms/step - loss: 0.0038 - val_loss: 0.0040\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 20s 93ms/step - loss: 0.0035 - val_loss: 0.0037\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 20s 93ms/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0033 - val_loss: 0.0034\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0032 - val_loss: 0.0035\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0032 - val_loss: 0.0033\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0031 - val_loss: 0.0033\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 21s 95ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0030 - val_loss: 0.0032\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0030 - val_loss: 0.0034\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 20s 93ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0029 - val_loss: 0.0031\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "(None, None, 20)\n",
            "(None, 20)\n",
            "(None, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkl8HiKuMpc4"
      },
      "source": [
        "#forecasting several steps ahead\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "np.set_printoptions(linewidth=2000)\n",
        "series = generate_time_series(1, n_steps + 10)\n",
        "print(series.shape)\n",
        "X_new, y_new = series[:, :n_steps], series[:, n_steps:]\n",
        "X = X_new\n",
        "y0 = np.empty((1,1,1))\n",
        "y1 = np.empty((1,1,1))\n",
        "for step_ahead in range(10):\n",
        "  y_pred = model.predict(X[:, step_ahead:])\n",
        "  print(y_pred)\n",
        "  y_pred_one = model.predict(X[:, step_ahead:])[..., np.newaxis] #dołóż nową oś by concatenate nie wyjebało w kosmos\n",
        "  y0 = np.concatenate([y0, y_pred_one], axis = 1)\n",
        "  y_pred_two = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
        "  y1 = np.concatenate([y1, y_pred_two], axis = 1)\n",
        "  # tu się roluje, czyli bierze od kroku 0 do 50 i przewiduje 51, potem, gdy step_ahead=1 bierze X od kroku 1 do 51 (gdy się przypnie przewidywanie nr 51) i przewiduje 52 itd.\n",
        "  X = np.concatenate([X, y_pred_one], axis = 1)\n",
        "  \n",
        "\n",
        "print(y0)\n",
        "print(y1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvdFU1noB08p"
      },
      "source": [
        "z = np.empty((2,4))\n",
        "print(z)\n",
        "z = z[:, np.newaxis, :]\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb4z4-atIsI3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c1c5397c-c9ee-4780-96ef-a71c0f864c49"
      },
      "source": [
        "z = np.empty((2,4))\n",
        "print(z)\n",
        "z = z[:, :, np.newaxis]\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.73607087  0.35755464  0.01855573  0.34476936]\n",
            " [ 0.60988677  0.73854846  0.66767079  0.4298614 ]]\n",
            "[[[10.73607087]\n",
            "  [ 0.35755464]\n",
            "  [ 0.01855573]\n",
            "  [ 0.34476936]]\n",
            "\n",
            " [[ 0.60988677]\n",
            "  [ 0.73854846]\n",
            "  [ 0.66767079]\n",
            "  [ 0.4298614 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WJzL7wBI4L2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8c63e292-eb7b-4ba4-c416-8481dea84800"
      },
      "source": [
        "z = np.empty((2,4))\n",
        "print(z)\n",
        "z = z[np.newaxis, :]\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.73607087  0.35755464  0.01855573  0.34476936]\n",
            " [ 0.60988677  0.73854846  0.66767079  0.4298614 ]]\n",
            "[[[10.73607087  0.35755464  0.01855573  0.34476936]\n",
            "  [ 0.60988677  0.73854846  0.66767079  0.4298614 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU-EoaK4I_IF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "923a9611-86e0-416c-a2a2-d3f9c66490bf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10.73607087 -0.35755464 -0.01855573  0.34476936  0.60988677  0.73854846  0.66767079  0.4298614   0.11216023 -0.19946051]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6a14442f6b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQan-44zJFLj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "99dd40cd-eeef-47e7-f8e3-9f1d1fe12a0d"
      },
      "source": [
        "# instead of predicting one by one we can predict all at once\n",
        "# performance is better\n",
        "series = generate_time_series(10000, n_steps + 10)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
        "X_test, y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None,1]),\n",
        "                                 keras.layers.SimpleRNN(20),\n",
        "                                 keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)\n",
        "\n",
        "X_new = series[:, :n_steps]\n",
        "Y_pred = model.predict(X_new)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 21s 97ms/step - loss: 0.1328 - val_loss: 0.0704\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0543 - val_loss: 0.0383\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0356 - val_loss: 0.0311\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 22s 99ms/step - loss: 0.0279 - val_loss: 0.0263\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.0238 - val_loss: 0.0215\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 22s 100ms/step - loss: 0.0212 - val_loss: 0.0204\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 22s 100ms/step - loss: 0.0190 - val_loss: 0.0172\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0175 - val_loss: 0.0168\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.0165 - val_loss: 0.0271\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.0155 - val_loss: 0.0141\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0143 - val_loss: 0.0164\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 22s 99ms/step - loss: 0.0137 - val_loss: 0.0117\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0131 - val_loss: 0.0120\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 22s 99ms/step - loss: 0.0123 - val_loss: 0.0116\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 22s 98ms/step - loss: 0.0116 - val_loss: 0.0109\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 21s 97ms/step - loss: 0.0112 - val_loss: 0.0098\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 22s 99ms/step - loss: 0.0106 - val_loss: 0.0098\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 22s 100ms/step - loss: 0.0103 - val_loss: 0.0092\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 21s 97ms/step - loss: 0.0096 - val_loss: 0.0100\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.0094 - val_loss: 0.0088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqdlNkacLQf-"
      },
      "source": [
        "loss = keras.losses.MeanSquaredError(series[:, n_steps:], Y_pred[:, np.newaxis, :])\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgxFpSisLdgB"
      },
      "source": [
        "#instead of predicting 10 values at the last step we can predict 10 next values at every steo\n",
        "#in other words from seqtovec to seqtoseq\n",
        "#more gradients that will flow not only from teh end output throughtout time, but also from output of each time step\n",
        "Y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Ju8uOGNj_4"
      },
      "source": [
        "series[:, n_steps:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhreGLDFPvmL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7223f6dd-f82b-40d5-a77a-97d26dba91a9"
      },
      "source": [
        "np.mean(keras.losses.mean_squared_error(series[:, n_steps:], Y_pred[:, np.newaxis]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3919288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpPaZExnVUg7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df9c10e5-7e7a-44b7-ae3c-0994e5a37979"
      },
      "source": [
        "series[:, n_steps:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaAplP31Vdpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c961f5f6-0caf-4443-9dcd-dba2885a2dd7"
      },
      "source": [
        "Y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjWe3hYqVffD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa0170c7-0106-471c-bf1f-c6bae976d213"
      },
      "source": [
        "Y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlOEprKlV7Rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "763bc1a3-1899-40be-cb54-7ac60e0ab608"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.SimpleRNN(20),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 92/219 [===========>..................] - ETA: 11s - loss: 0.2789"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e7ba1bdd1c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m history = model.fit(X_train, Y_train, epochs=20,\n\u001b[0;32m---> 12\u001b[0;31m                     validation_data=(X_valid, Y_valid))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVnoX4jiiU8x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "5c339144-bbfc-4d08-9a1a-1988e53dc8ad"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 10)\n",
        "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
        "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
        "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.SimpleRNN(20),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 21s 94ms/step - loss: 0.1295 - val_loss: 0.0651\n",
            "Epoch 2/20\n",
            " 72/219 [========>.....................] - ETA: 13s - loss: 0.0622"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-4c976840526c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m history = model.fit(X_train, Y_train, epochs=20,\n\u001b[0;32m---> 21\u001b[0;31m                     validation_data=(X_valid, Y_valid))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYhcl4FUlCF0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B_Qii5BlB8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "f2ed3580-520f-4d0d-86a2-b8e974b1c1a7"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 10)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
        "X_test, y_test = series[9000:, :n_steps], series[9000:, -10:, 0]\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None,1]),\n",
        "                                 keras.layers.SimpleRNN(20),\n",
        "                                 keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)\n",
        "\n",
        "X_new = series[:, :n_steps]\n",
        "Y_pred = model.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.1326 - val_loss: 0.0649\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 21s 96ms/step - loss: 0.0518 - val_loss: 0.0402\n",
            "Epoch 3/20\n",
            "117/219 [===============>..............] - ETA: 9s - loss: 0.0398"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-382bcdf62206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m ])\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nadam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ca4VWF7lDWn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "bc30e702-5191-4eaa-a35d-c40b565d0b11"
      },
      "source": [
        "\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None,1]),\n",
        "                                 keras.layers.SimpleRNN(20),\n",
        "                                 keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.1131 - val_loss: 0.0592\n",
            "Epoch 2/20\n",
            " 61/219 [=======>......................] - ETA: 15s - loss: 0.0559"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-34b8446b161b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nadam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG-GH6fxz97j"
      },
      "source": [
        "# ten steps ahead for all points \n",
        "# so having just t0 you predict t1-11, t0:1 - t2-12, ... , t0:50 - t51-60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCk0bcofl9Ki"
      },
      "source": [
        "Y = np.empty((10000, n_steps, 10)) #10000 tables * 60 steps * 10 predictions for each step\n",
        "for step_ahead in range(1, 10+ 1):\n",
        "  Y[:, :, step_ahead - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca23KLrc02td",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "series[:, 5:5+n_steps, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij0Dr76s06eB",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d55e3f78-d211-4587-a417-b9c12dce6fc8"
      },
      "source": [
        "5+n_steps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 22s 100ms/step - loss: 0.0859 - last_time_step_mse: 0.0645 - val_loss: 0.0501 - val_last_time_step_mse: 0.0280\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.0423 - last_time_step_mse: 0.0204 - val_loss: 0.0363 - val_last_time_step_mse: 0.0166\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 21s 98ms/step - loss: 0.0343 - last_time_step_mse: 0.0152 - val_loss: 0.0317 - val_last_time_step_mse: 0.0146\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 21s 95ms/step - loss: 0.0319 - last_time_step_mse: 0.0151 - val_loss: 0.0283 - val_last_time_step_mse: 0.0118\n",
            "Epoch 5/20\n",
            " 23/219 [==>...........................] - ETA: 18s - loss: 0.0283 - last_time_step_mse: 0.0115"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-0b33d0247a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_time_step_mse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcvDuzea1FwU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "336c88f3-f129-483a-f835-d102ee64aac5"
      },
      "source": [
        "#few steps ahead at each and every point\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 10)\n",
        "X_train = series[:7000, :n_steps]\n",
        "X_valid = series[7000:9000, :n_steps]\n",
        "X_test = series[9000:, :n_steps]\n",
        "Y = np.empty((10000, n_steps, 10))\n",
        "for step_ahead in range(1, 10 + 1):\n",
        "    Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]\n",
        "Y_train = Y[:7000]\n",
        "Y_valid = Y[7000:9000]\n",
        "Y_test = Y[9000:]\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
        "])\n",
        "\n",
        "def last_time_step_mse(Y_true, Y_pred):\n",
        "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(lr=0.01), metrics=[last_time_step_mse])\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0806 - last_time_step_mse: 0.0609 - val_loss: 0.0476 - val_last_time_step_mse: 0.0279\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0420 - last_time_step_mse: 0.0221 - val_loss: 0.0365 - val_last_time_step_mse: 0.0181\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 20s 91ms/step - loss: 0.0349 - last_time_step_mse: 0.0169 - val_loss: 0.0314 - val_last_time_step_mse: 0.0132\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0313 - last_time_step_mse: 0.0140 - val_loss: 0.0290 - val_last_time_step_mse: 0.0120\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 20s 89ms/step - loss: 0.0286 - last_time_step_mse: 0.0117 - val_loss: 0.0280 - val_last_time_step_mse: 0.0104\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 20s 91ms/step - loss: 0.0279 - last_time_step_mse: 0.0115 - val_loss: 0.0255 - val_last_time_step_mse: 0.0086\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0263 - last_time_step_mse: 0.0102 - val_loss: 0.0263 - val_last_time_step_mse: 0.0100\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0264 - last_time_step_mse: 0.0104 - val_loss: 0.0267 - val_last_time_step_mse: 0.0108\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 20s 93ms/step - loss: 0.0256 - last_time_step_mse: 0.0099 - val_loss: 0.0248 - val_last_time_step_mse: 0.0091\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 20s 93ms/step - loss: 0.0254 - last_time_step_mse: 0.0099 - val_loss: 0.0246 - val_last_time_step_mse: 0.0092\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0259 - last_time_step_mse: 0.0103 - val_loss: 0.0290 - val_last_time_step_mse: 0.0135\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 20s 93ms/step - loss: 0.0250 - last_time_step_mse: 0.0095 - val_loss: 0.0247 - val_last_time_step_mse: 0.0091\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0239 - last_time_step_mse: 0.0083 - val_loss: 0.0231 - val_last_time_step_mse: 0.0076\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 20s 90ms/step - loss: 0.0244 - last_time_step_mse: 0.0089 - val_loss: 0.0234 - val_last_time_step_mse: 0.0077\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 20s 91ms/step - loss: 0.0237 - last_time_step_mse: 0.0082 - val_loss: 0.0228 - val_last_time_step_mse: 0.0075\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0239 - last_time_step_mse: 0.0087 - val_loss: 0.0253 - val_last_time_step_mse: 0.0096\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0237 - last_time_step_mse: 0.0084 - val_loss: 0.0231 - val_last_time_step_mse: 0.0078\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 20s 91ms/step - loss: 0.0236 - last_time_step_mse: 0.0083 - val_loss: 0.0241 - val_last_time_step_mse: 0.0094\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 20s 92ms/step - loss: 0.0241 - last_time_step_mse: 0.0089 - val_loss: 0.0236 - val_last_time_step_mse: 0.0089\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 20s 91ms/step - loss: 0.0244 - last_time_step_mse: 0.0095 - val_loss: 0.0232 - val_last_time_step_mse: 0.0083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NDaVxlc_7tf"
      },
      "source": [
        "#deep rnn with layer normalizatio\n",
        "\n",
        "#we have two problems with rnns\n",
        "#unstable gradients and short memory\n",
        "#to deal with gradients we can use most techniques we know (proper initialization, faster optimizers, dropout etc. batch normalization doesn't work well)\n",
        "#we have one more new tool - layer normalization\n",
        "# instead of normalizing across a batch it normalizes across features\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "\n",
        "#this will do  exactly the same as SimpleRNNCell with also Layer Norm at each time step\n",
        "class LNSimpleRNNCell(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.state_size = units\n",
        "        self.output_size = units\n",
        "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
        "                                                          activation=None)\n",
        "        self.layer_norm = LayerNormalization()\n",
        "        self.activation = keras.activations.get(activation)\n",
        "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
        "        if inputs is not None:\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "            dtype = inputs.dtype\n",
        "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
        "    def call(self, inputs, states):\n",
        "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
        "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
        "        return norm_outputs, [norm_outputs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F-PJCGRBe-N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "30c2f5a6-3a29-4c6c-cbd9-3f6e6c84944f"
      },
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
        "                     input_shape=[None, 1]),\n",
        "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
        "history = model.fit(X_train, Y_train, epochs=20, verbose =3,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F4NW2-iDfTU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "16413ec7-01c3-45fe-fd61-201bd5d114a5"
      },
      "source": [
        "#my first LSTM\n",
        "model = keras.models.Sequential([\n",
        "                                 keras.layers.LSTM(20, return_sequences=True, input_shape=[None,1]),\n",
        "                                 keras.layers.LSTM(20, return_sequences=True),\n",
        "                                 keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\" , metrics=[last_time_step_mse])\n",
        "history = model.fit(X_train, Y_train, epochs=20, verbose =2,\n",
        "\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 - 5s - loss: 0.1667 - last_time_step_mse: 0.1497 - val_loss: 0.1011 - val_last_time_step_mse: 0.0694\n",
            "Epoch 2/20\n",
            "219/219 - 4s - loss: 0.0792 - last_time_step_mse: 0.0433 - val_loss: 0.0649 - val_last_time_step_mse: 0.0274\n",
            "Epoch 3/20\n",
            "219/219 - 4s - loss: 0.0580 - last_time_step_mse: 0.0210 - val_loss: 0.0526 - val_last_time_step_mse: 0.0168\n",
            "Epoch 4/20\n",
            "219/219 - 4s - loss: 0.0485 - last_time_step_mse: 0.0141 - val_loss: 0.0452 - val_last_time_step_mse: 0.0127\n",
            "Epoch 5/20\n",
            "219/219 - 4s - loss: 0.0429 - last_time_step_mse: 0.0108 - val_loss: 0.0411 - val_last_time_step_mse: 0.0105\n",
            "Epoch 6/20\n",
            "219/219 - 4s - loss: 0.0395 - last_time_step_mse: 0.0095 - val_loss: 0.0383 - val_last_time_step_mse: 0.0089\n",
            "Epoch 7/20\n",
            "219/219 - 4s - loss: 0.0372 - last_time_step_mse: 0.0088 - val_loss: 0.0359 - val_last_time_step_mse: 0.0080\n",
            "Epoch 8/20\n",
            "219/219 - 4s - loss: 0.0353 - last_time_step_mse: 0.0081 - val_loss: 0.0344 - val_last_time_step_mse: 0.0073\n",
            "Epoch 9/20\n",
            "219/219 - 4s - loss: 0.0339 - last_time_step_mse: 0.0076 - val_loss: 0.0338 - val_last_time_step_mse: 0.0082\n",
            "Epoch 10/20\n",
            "219/219 - 4s - loss: 0.0326 - last_time_step_mse: 0.0072 - val_loss: 0.0318 - val_last_time_step_mse: 0.0068\n",
            "Epoch 11/20\n",
            "219/219 - 4s - loss: 0.0314 - last_time_step_mse: 0.0068 - val_loss: 0.0312 - val_last_time_step_mse: 0.0067\n",
            "Epoch 12/20\n",
            "219/219 - 4s - loss: 0.0306 - last_time_step_mse: 0.0067 - val_loss: 0.0301 - val_last_time_step_mse: 0.0064\n",
            "Epoch 13/20\n",
            "219/219 - 5s - loss: 0.0296 - last_time_step_mse: 0.0063 - val_loss: 0.0291 - val_last_time_step_mse: 0.0063\n",
            "Epoch 14/20\n",
            "219/219 - 4s - loss: 0.0288 - last_time_step_mse: 0.0061 - val_loss: 0.0284 - val_last_time_step_mse: 0.0060\n",
            "Epoch 15/20\n",
            "219/219 - 4s - loss: 0.0280 - last_time_step_mse: 0.0059 - val_loss: 0.0279 - val_last_time_step_mse: 0.0059\n",
            "Epoch 16/20\n",
            "219/219 - 4s - loss: 0.0274 - last_time_step_mse: 0.0058 - val_loss: 0.0271 - val_last_time_step_mse: 0.0059\n",
            "Epoch 17/20\n",
            "219/219 - 4s - loss: 0.0267 - last_time_step_mse: 0.0057 - val_loss: 0.0263 - val_last_time_step_mse: 0.0056\n",
            "Epoch 18/20\n",
            "219/219 - 4s - loss: 0.0262 - last_time_step_mse: 0.0057 - val_loss: 0.0256 - val_last_time_step_mse: 0.0051\n",
            "Epoch 19/20\n",
            "219/219 - 4s - loss: 0.0256 - last_time_step_mse: 0.0054 - val_loss: 0.0254 - val_last_time_step_mse: 0.0058\n",
            "Epoch 20/20\n",
            "219/219 - 4s - loss: 0.0251 - last_time_step_mse: 0.0053 - val_loss: 0.0247 - val_last_time_step_mse: 0.0053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfLgQCq7H3zY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "1dafa7eb-710b-4f5c-e419-aeb548174a69"
      },
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 10)\n",
        "X_train = series[:7000, :n_steps]\n",
        "X_valid = series[7000:9000, :n_steps]\n",
        "X_test = series[9000:, :n_steps]\n",
        "Y = np.empty((10000, n_steps, 10))\n",
        "for step_ahead in range(1, 10 + 1):\n",
        "    Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]\n",
        "Y_train = Y[:7000]\n",
        "Y_valid = Y[7000:9000]\n",
        "Y_test = Y[9000:]\n",
        "def last_time_step_mse(Y_true, Y_pred):\n",
        "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
        "                        input_shape=[None, 1]),\n",
        "    keras.layers.GRU(20, return_sequences=True),\n",
        "    keras.layers.GRU(20, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
        "history = model.fit(X_train, Y_train[:, 3::2], epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid[:, 3::2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.1388 - last_time_step_mse: 0.1302 - val_loss: 0.0827 - val_last_time_step_mse: 0.0710\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0696 - last_time_step_mse: 0.0553 - val_loss: 0.0553 - val_last_time_step_mse: 0.0402\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0474 - last_time_step_mse: 0.0308 - val_loss: 0.0403 - val_last_time_step_mse: 0.0245\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0360 - last_time_step_mse: 0.0196 - val_loss: 0.0322 - val_last_time_step_mse: 0.0168\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0296 - last_time_step_mse: 0.0140 - val_loss: 0.0274 - val_last_time_step_mse: 0.0122\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0257 - last_time_step_mse: 0.0106 - val_loss: 0.0244 - val_last_time_step_mse: 0.0099\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0233 - last_time_step_mse: 0.0088 - val_loss: 0.0223 - val_last_time_step_mse: 0.0080\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0218 - last_time_step_mse: 0.0076 - val_loss: 0.0211 - val_last_time_step_mse: 0.0070\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0206 - last_time_step_mse: 0.0068 - val_loss: 0.0202 - val_last_time_step_mse: 0.0065\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0196 - last_time_step_mse: 0.0062 - val_loss: 0.0192 - val_last_time_step_mse: 0.0057\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0189 - last_time_step_mse: 0.0058 - val_loss: 0.0187 - val_last_time_step_mse: 0.0055\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0183 - last_time_step_mse: 0.0054 - val_loss: 0.0182 - val_last_time_step_mse: 0.0053\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0177 - last_time_step_mse: 0.0052 - val_loss: 0.0176 - val_last_time_step_mse: 0.0049\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0172 - last_time_step_mse: 0.0050 - val_loss: 0.0175 - val_last_time_step_mse: 0.0052\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0168 - last_time_step_mse: 0.0049 - val_loss: 0.0170 - val_last_time_step_mse: 0.0049\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0164 - last_time_step_mse: 0.0046 - val_loss: 0.0163 - val_last_time_step_mse: 0.0045\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0159 - last_time_step_mse: 0.0045 - val_loss: 0.0158 - val_last_time_step_mse: 0.0042\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0155 - last_time_step_mse: 0.0043 - val_loss: 0.0155 - val_last_time_step_mse: 0.0041\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0152 - last_time_step_mse: 0.0042 - val_loss: 0.0153 - val_last_time_step_mse: 0.0043\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0148 - last_time_step_mse: 0.0040 - val_loss: 0.0148 - val_last_time_step_mse: 0.0038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7K5pMkTaTMT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "e89f368f-0085-4024-88f2-bb725897e52d"
      },
      "source": [
        "#wavenet\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
        "for rate in (1, 2, 4, 8) * 2:\n",
        "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",\n",
        "                                  activation=\"relu\", dilation_rate=rate))\n",
        "model.add(keras.layers.Conv1D(filters=10, kernel_size=1)) # final layer to predict 10 next values\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1176 - last_time_step_mse: 0.0984 - val_loss: 0.0543 - val_last_time_step_mse: 0.0334\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0472 - last_time_step_mse: 0.0261 - val_loss: 0.0415 - val_last_time_step_mse: 0.0220\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0391 - last_time_step_mse: 0.0194 - val_loss: 0.0367 - val_last_time_step_mse: 0.0180\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0351 - last_time_step_mse: 0.0159 - val_loss: 0.0332 - val_last_time_step_mse: 0.0148\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0323 - last_time_step_mse: 0.0134 - val_loss: 0.0316 - val_last_time_step_mse: 0.0134\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0305 - last_time_step_mse: 0.0120 - val_loss: 0.0297 - val_last_time_step_mse: 0.0120\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0291 - last_time_step_mse: 0.0112 - val_loss: 0.0281 - val_last_time_step_mse: 0.0106\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0279 - last_time_step_mse: 0.0102 - val_loss: 0.0272 - val_last_time_step_mse: 0.0099\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0269 - last_time_step_mse: 0.0096 - val_loss: 0.0266 - val_last_time_step_mse: 0.0094\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0262 - last_time_step_mse: 0.0091 - val_loss: 0.0261 - val_last_time_step_mse: 0.0092\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0255 - last_time_step_mse: 0.0087 - val_loss: 0.0253 - val_last_time_step_mse: 0.0087\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0250 - last_time_step_mse: 0.0085 - val_loss: 0.0248 - val_last_time_step_mse: 0.0085\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0244 - last_time_step_mse: 0.0079 - val_loss: 0.0241 - val_last_time_step_mse: 0.0079\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0239 - last_time_step_mse: 0.0076 - val_loss: 0.0237 - val_last_time_step_mse: 0.0078\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0236 - last_time_step_mse: 0.0076 - val_loss: 0.0234 - val_last_time_step_mse: 0.0073\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0233 - last_time_step_mse: 0.0075 - val_loss: 0.0233 - val_last_time_step_mse: 0.0074\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0230 - last_time_step_mse: 0.0072 - val_loss: 0.0230 - val_last_time_step_mse: 0.0072\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0226 - last_time_step_mse: 0.0068 - val_loss: 0.0228 - val_last_time_step_mse: 0.0070\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0224 - last_time_step_mse: 0.0068 - val_loss: 0.0225 - val_last_time_step_mse: 0.0071\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0222 - last_time_step_mse: 0.0066 - val_loss: 0.0231 - val_last_time_step_mse: 0.0077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnDYzRZJgmOt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}