{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH15_SET10_with_notes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaC9ES7FKxryQLWFkg7Lq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qamtam/Hands-on-machine-learning/blob/main/CH15_SET10_with_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJViCi7u-uRk"
      },
      "source": [
        "\n",
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "np.set_printoptions(threshold=np.inf) # print pretty pony tables\n",
        "np.set_printoptions(linewidth=2000)\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"rnn\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0wHHZSF_CtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad3efad-f8c2-403e-84b7-3ec4d0b6b057"
      },
      "source": [
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/jsb_chorales/jsb_chorales.tgz\"\n",
        "FILENAME = \"jsb_chorales.tgz\"\n",
        "\n",
        "filepath = keras.utils.get_file(FILENAME,\n",
        "                                DOWNLOAD_ROOT,\n",
        "                                cache_subdir=\"datasets/bach\",\n",
        "                                extract=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/jsb_chorales/jsb_chorales.tgz\n",
            "122880/117661 [===============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEH36gQS_Q9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646532bd-40a9-4a37-9cf4-c887ea67ab68"
      },
      "source": [
        "root = os.path.join(\"/root/.keras/datasets/bach\")\n",
        "bach_dir = Path(filepath).parent\n",
        "os.path.abspath(bach_dir)\n",
        "os.listdir(bach_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'valid', 'jsb_chorales.tgz', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvoJcsKl_i4l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifA3kaV1_lgW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "846b5f79-6b87-40bb-9835-1ac5fa0a94ab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3e2f77882c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'val_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnV0_7eT_z8A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZhIn6vF_55o"
      },
      "source": [
        "train_path = bach_dir / \"train\"\n",
        "val_path = bach_dir / \"valid\"\n",
        "test_path = bach_dir / \"test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izJKqcreA2Gi"
      },
      "source": [
        "train_files = [str(path) for path in os.listdir(train_path)]\n",
        "valid_files = [str(path) for path in os.listdir(val_path)]\n",
        "test_files = [str(path) for path in os.listdir(test_path)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wfx55eAHYRn"
      },
      "source": [
        "train_paths = [os.path.join(os.path.abspath(bach_dir), \"train\", x) for x in train_files]\n",
        "valid_paths = [os.path.join(os.path.abspath(bach_dir), \"valid\", x) for x in valid_files]\n",
        "test_paths = [os.path.join(os.path.abspath(bach_dir), \"test\", x) for x in test_files]\n",
        "\n",
        "n_inputs=4\n",
        "\n",
        "\n",
        "def preprocess(line):\n",
        "  defs = [0.] * n_inputs\n",
        "  fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "  results = tf.stack(fields)\n",
        "  return results\n",
        "\n",
        "def read_bach_notes_from_csv(filepaths, repeat=1, n_readers=5, n_read_threads=None, shuffle_buffer_size=10000, n_parse_threads=5, batch_size=32):\n",
        "  dataset= tf.data.Dataset.list_files(filepaths) #creates a dataset of filepaths\n",
        "  dataset = dataset.map(lambda x: tf.data.TextLineDataset(x))\n",
        "  for x in dataset:\n",
        "    print(x)\n",
        "  #dataset = dataset.map(preprocess)\n",
        "  dataset = dataset.repeat(repeat)\n",
        "  return dataset.batch(batch_size).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsugztAoBOaY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "train = read_bach_notes_from_csv(train_paths)\n",
        "valid = read_bach_notes_from_csv(valid_paths)\n",
        "test = read_bach_notes_from_csv(test_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNn80sUuLSB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00dd9ce7-db91-4796-8caa-45b6804b87bc"
      },
      "source": [
        "for x in train.take(100):\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[74. 69. 66. 62.]\n",
            " [74. 69. 66. 62.]\n",
            " [74. 69. 64. 61.]\n",
            " [74. 69. 64. 61.]\n",
            " [74. 69. 62. 59.]\n",
            " [74. 69. 62. 59.]\n",
            " [74. 67. 62. 59.]\n",
            " [74. 67. 62. 59.]\n",
            " [74. 66. 60. 57.]\n",
            " [74. 66. 60. 57.]\n",
            " [74. 67. 59. 55.]\n",
            " [74. 67. 59. 55.]\n",
            " [69. 69. 62. 54.]\n",
            " [69. 69. 62. 54.]\n",
            " [71. 66. 62. 54.]\n",
            " [71. 66. 62. 54.]\n",
            " [73. 67. 64. 52.]\n",
            " [73. 67. 64. 52.]\n",
            " [73. 69. 64. 52.]\n",
            " [73. 69. 64. 52.]\n",
            " [74. 66. 57. 50.]\n",
            " [74. 66. 57. 50.]\n",
            " [73. 64. 57. 50.]\n",
            " [73. 64. 57. 50.]\n",
            " [71. 62. 57. 52.]\n",
            " [71. 62. 57. 52.]\n",
            " [71. 64. 56. 52.]\n",
            " [71. 64. 56. 52.]\n",
            " [69. 61. 57. 45.]\n",
            " [69. 61. 57. 45.]\n",
            " [69. 61. 57. 45.]\n",
            " [69. 61. 57. 45.]], shape=(32, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[74. 66. 54. 47.]\n",
            " [74. 66. 54. 47.]\n",
            " [74. 66. 56. 47.]\n",
            " [74. 66. 56. 47.]\n",
            " [73. 64. 57. 49.]\n",
            " [73. 64. 57. 49.]\n",
            " [73. 66. 57. 50.]\n",
            " [73. 66. 57. 50.]\n",
            " [71. 67. 64. 52.]\n",
            " [71. 67. 64. 52.]\n",
            " [71. 67. 62. 52.]\n",
            " [71. 67. 62. 52.]\n",
            " [69. 66. 61. 54.]\n",
            " [69. 66. 61. 54.]\n",
            " [69. 64. 61. 54.]\n",
            " [69. 64. 61. 54.]\n",
            " [71. 62. 59. 55.]\n",
            " [71. 62. 59. 55.]\n",
            " [69. 62. 61. 57.]\n",
            " [69. 62. 61. 57.]\n",
            " [67. 62. 62. 59.]\n",
            " [67. 62. 62. 59.]\n",
            " [66. 62. 62. 55.]\n",
            " [66. 62. 62. 55.]\n",
            " [64. 61. 57. 57.]\n",
            " [64. 61. 57. 57.]\n",
            " [64. 61. 55. 45.]\n",
            " [64. 61. 55. 45.]\n",
            " [62. 57. 54. 50.]\n",
            " [62. 57. 54. 50.]\n",
            " [62. 57. 54. 50.]\n",
            " [62. 57. 54. 50.]], shape=(32, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[74. 69. 66. 62.]\n",
            " [74. 69. 66. 62.]\n",
            " [74. 69. 64. 61.]\n",
            " [74. 69. 64. 61.]\n",
            " [74. 69. 62. 59.]\n",
            " [74. 69. 62. 59.]\n",
            " [74. 67. 62. 59.]\n",
            " [74. 67. 62. 59.]\n",
            " [74. 66. 60. 57.]\n",
            " [74. 66. 60. 57.]\n",
            " [74. 67. 59. 55.]\n",
            " [74. 67. 59. 55.]\n",
            " [69. 69. 62. 54.]\n",
            " [69. 69. 62. 54.]\n",
            " [71. 66. 62. 54.]\n",
            " [71. 66. 62. 54.]\n",
            " [73. 67. 64. 52.]\n",
            " [73. 67. 64. 52.]\n",
            " [73. 69. 64. 52.]\n",
            " [73. 69. 64. 52.]\n",
            " [74. 66. 57. 50.]\n",
            " [74. 66. 57. 50.]\n",
            " [73. 64. 57. 50.]\n",
            " [73. 64. 57. 50.]\n",
            " [71. 62. 57. 52.]\n",
            " [71. 62. 57. 52.]\n",
            " [71. 64. 56. 52.]\n",
            " [71. 64. 56. 52.]\n",
            " [69. 61. 57. 45.]\n",
            " [69. 61. 57. 45.]\n",
            " [69. 61. 57. 45.]\n",
            " [69. 61. 57. 45.]], shape=(32, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[74. 66. 54. 47.]\n",
            " [74. 66. 54. 47.]\n",
            " [74. 66. 56. 47.]\n",
            " [74. 66. 56. 47.]\n",
            " [73. 64. 57. 49.]\n",
            " [73. 64. 57. 49.]\n",
            " [73. 66. 57. 50.]\n",
            " [73. 66. 57. 50.]\n",
            " [71. 67. 64. 52.]\n",
            " [71. 67. 64. 52.]\n",
            " [71. 67. 62. 52.]\n",
            " [71. 67. 62. 52.]\n",
            " [69. 66. 61. 54.]\n",
            " [69. 66. 61. 54.]\n",
            " [69. 64. 61. 54.]\n",
            " [69. 64. 61. 54.]\n",
            " [71. 62. 59. 55.]\n",
            " [71. 62. 59. 55.]\n",
            " [69. 62. 61. 57.]\n",
            " [69. 62. 61. 57.]\n",
            " [67. 62. 62. 59.]\n",
            " [67. 62. 62. 59.]\n",
            " [66. 62. 62. 55.]\n",
            " [66. 62. 62. 55.]\n",
            " [64. 61. 57. 57.]\n",
            " [64. 61. 57. 57.]\n",
            " [64. 61. 55. 45.]\n",
            " [64. 61. 55. 45.]\n",
            " [62. 57. 54. 50.]\n",
            " [62. 57. 54. 50.]\n",
            " [62. 57. 54. 50.]\n",
            " [62. 57. 54. 50.]], shape=(32, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[62. 62. 54. 50.]\n",
            " [62. 62. 54. 50.]\n",
            " [62. 62. 56. 52.]\n",
            " [62. 62. 56. 52.]\n",
            " [69. 61. 57. 54.]\n",
            " [69. 61. 57. 54.]\n",
            " [69. 66. 62. 54.]\n",
            " [69. 66. 62. 54.]\n",
            " [71. 64. 61. 56.]\n",
            " [71. 64. 61. 56.]\n",
            " [71. 62. 59. 56.]\n",
            " [71. 62. 59. 56.]\n",
            " [69. 61. 64. 57.]\n",
            " [69. 61. 64. 57.]\n",
            " [69. 62. 66. 50.]\n",
            " [69. 62. 66. 50.]\n",
            " [68. 59. 64. 52.]\n",
            " [68. 59. 64. 52.]\n",
            " [68. 59. 62. 52.]\n",
            " [68. 59. 62. 52.]\n",
            " [69. 57. 61. 45.]\n",
            " [69. 57. 61. 45.]\n",
            " [69. 57. 61. 45.]\n",
            " [69. 57. 61. 45.]\n",
            " [62. 62. 54. 47.]\n",
            " [62. 62. 54. 47.]\n",
            " [62. 62. 55. 47.]\n",
            " [62. 62. 55. 47.]\n",
            " [69. 62. 57. 54.]\n",
            " [69. 62. 57. 54.]\n",
            " [69. 62. 57. 54.]\n",
            " [69. 62. 57. 54.]], shape=(32, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[71. 67. 64. 52.]\n",
            " [71. 67. 64. 52.]\n",
            " [73. 67. 64. 45.]\n",
            " [73. 67. 64. 45.]\n",
            " [74. 66. 62. 50.]\n",
            " [74. 66. 62. 50.]\n",
            " [74. 66. 62. 50.]\n",
            " [74. 66. 62. 50.]\n",
            " [73. 66. 57. 54.]\n",
            " [73. 66. 57. 54.]\n",
            " [73. 66. 57. 54.]\n",
            " [73. 66. 57. 54.]\n",
            " [74. 66. 59. 47.]\n",
            " [74. 68. 59. 47.]\n",
            " [73. 69. 64. 52.]\n",
            " [73. 69. 64. 52.]\n",
            " [71. 69. 66. 50.]\n",
            " [71. 69. 66. 50.]\n",
            " [71. 68. 64. 52.]\n",
            " [71. 68. 64. 52.]\n",
            " [69. 69. 61. 45.]\n",
            " [69. 69. 61. 45.]\n",
            " [69. 69. 61. 45.]\n",
            " [69. 69. 61. 45.]\n",
            " [71. 67. 59. 52.]\n",
            " [71. 67. 59. 52.]\n",
            " [71. 67. 61. 52.]\n",
            " [71. 67. 61. 52.]\n",
            " [71. 67. 62. 47.]\n",
            " [71. 67. 62. 47.]\n",
            " [71. 67. 62. 49.]\n",
            " [71. 67. 62. 49.]], shape=(32, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[69. 66. 62. 50.]\n",
            " [69. 66. 62. 50.]\n",
            " [69. 66. 60. 50.]\n",
            " [69. 66. 60. 50.]\n",
            " [71. 66. 59. 51.]\n",
            " [71. 66. 59. 51.]\n",
            " [69. 66. 59. 51.]\n",
            " [69. 66. 59. 51.]\n",
            " [67. 64. 59. 52.]\n",
            " [67. 64. 59. 52.]\n",
            " [67. 64. 59. 52.]\n",
            " [67. 64. 59. 52.]\n",
            " [66. 63. 59. 47.]\n",
            " [66. 63. 59. 47.]\n",
            " [66. 63. 59. 47.]\n",
            " [66. 63. 59. 47.]\n",
            " [74. 66. 59. 47.]\n",
            " [74. 66. 59. 47.]\n",
            " [74. 68. 59. 47.]\n",
            " [74. 68. 59. 47.]\n",
            " [73. 69. 64. 49.]\n",
            " [73. 69. 64. 49.]\n",
            " [73. 69. 64. 50.]\n",
            " [73. 69. 64. 50.]\n",
            " [71. 67. 64. 52.]\n",
            " [71. 67. 64. 52.]\n",
            " [71. 67. 64. 50.]\n",
            " [71. 67. 64. 50.]\n",
            " [69. 67. 64. 49.]\n",
            " [69. 67. 64. 49.]\n",
            " [69. 67. 64. 45.]\n",
            " [69. 67. 64. 45.]], shape=(32, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2611\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Field 0 in record 0 is not a valid float: note0\n\t [[{{node DecodeCSV}}]] [Op:IteratorGetNext]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-6e2ced02f2d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Field 0 in record 0 is not a valid float: note0\n\t [[{{node DecodeCSV}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyjfF0MlCYRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba18182a-f9ce-4809-d3c2-e152501da5ba"
      },
      "source": [
        "zet = train_paths[0]\n",
        "zet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/bach/train/chorale_127.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWFrUvRUDiOv"
      },
      "source": [
        "data = tf.data.TextLineDataset(zet)\n",
        "for x in data:\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpfhktXkEV_5"
      },
      "source": [
        "z = train.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK37ijGtFaEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1ff021d-bf52-4f6f-ff57-aee1d8ad3ec6"
      },
      "source": [
        "files = tf.data.Dataset.list_files(train_paths)\n",
        "for x in files:\n",
        "\n",
        "  print(x)\n",
        "  print(\"new data set instance in the dataset \\n\")\n",
        "  \n",
        "dataset = files.map(lambda x: tf.string.to_string(x))\n",
        "\"\"\"\"\n",
        "\n",
        "dataset = files.map(lambda yomamma: tf.data.TextLineDataset(yomamma.as_string).skip(1))\n",
        "for x in dataset:\n",
        "  print(x)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_041.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_033.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_161.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_109.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_163.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_062.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_185.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_171.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_133.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_030.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_213.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_029.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_191.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_104.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_218.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_170.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_083.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_216.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_095.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_135.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_227.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_099.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_063.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_043.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_146.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_220.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_085.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_078.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_143.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_188.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_020.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_196.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_182.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_108.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_137.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_205.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_079.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_037.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_129.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_139.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_112.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_009.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_152.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_206.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_147.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_014.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_002.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_134.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_040.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_032.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_149.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_022.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_065.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_048.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_075.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_174.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_057.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_199.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_070.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_181.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_187.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_092.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_052.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_054.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_217.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_166.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_211.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_125.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_114.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_012.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_183.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_042.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_197.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_038.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_179.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_018.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_061.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_049.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_142.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_117.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_097.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_157.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_007.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_136.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_045.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_005.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_128.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_186.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_190.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_072.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_184.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_053.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_100.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_223.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_087.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_140.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_046.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_080.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_175.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_088.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_019.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_036.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_069.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_208.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_047.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_116.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_058.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_122.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_082.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_201.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_071.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_203.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_225.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_228.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_151.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_177.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_207.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_162.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_001.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_103.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_017.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_167.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_068.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_154.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_077.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_073.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_204.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_215.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_210.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_193.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_173.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_084.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_209.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_180.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_169.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_066.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_015.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_101.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_050.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_026.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_127.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_081.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_011.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_098.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_195.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_121.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_226.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_028.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_165.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_198.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_156.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_055.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_144.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_105.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_130.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_076.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_222.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_219.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_013.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_016.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_096.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_091.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_124.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_051.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_178.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_200.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_113.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_010.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_006.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_090.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_119.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_150.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_159.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_064.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_003.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_004.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_086.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_160.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_110.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_132.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_089.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_148.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_000.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_107.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_141.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_145.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_106.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_021.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_212.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_172.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_027.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_093.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_123.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_060.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_194.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_189.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_168.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_126.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_131.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_158.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_192.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_155.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_138.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_044.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_111.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_031.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_214.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_102.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_035.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_008.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_074.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_067.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_115.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_059.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_176.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_120.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_024.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_025.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_118.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_094.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_039.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_202.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_164.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_221.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_153.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_056.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_023.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_224.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n",
            "tf.Tensor(b'/root/.keras/datasets/bach/train/chorale_034.csv', shape=(), dtype=string)\n",
            "new data set instance in the dataset \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-af3a5d496647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new data set instance in the dataset \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \"\"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \"\"\"\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4046\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4047\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2939\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3363\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3364\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-88-af3a5d496647>:7 None  *\n        dataset = files.map(lambda x: tf.string.to_string(x))\n\n    AttributeError: 'DType' object has no attribute 'to_string'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyeqvsRKKgIz"
      },
      "source": [
        "z = 0\n",
        "for item in valid.take(1):\n",
        "  print(item)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5HHj3ATFumL"
      },
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "def notes_to_frequencies(notes):\n",
        "    # Frequency doubles when you go up one octave; there are 12 semi-tones\n",
        "    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.\n",
        "    return 2 ** ((np.array(notes) - 69) / 12) * 440\n",
        "\n",
        "def frequencies_to_samples(frequencies, tempo, sample_rate):\n",
        "    note_duration = 60 / tempo # the tempo is measured in beats per minutes\n",
        "    # To reduce click sound at every beat, we round the frequencies to try to\n",
        "    # get the samples close to zero at the end of each note.\n",
        "    frequencies = np.round(note_duration * frequencies) / note_duration\n",
        "    n_samples = int(note_duration * sample_rate)\n",
        "    time = np.linspace(0, note_duration, n_samples)\n",
        "    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)\n",
        "    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)\n",
        "    sine_waves *= (frequencies > 9.).reshape(-1, 1)\n",
        "    return sine_waves.reshape(-1)\n",
        "\n",
        "def chords_to_samples(chords, tempo, sample_rate):\n",
        "    freqs = notes_to_frequencies(chords)\n",
        "    freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer\n",
        "    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n",
        "                     for melody in freqs.T], axis=0)\n",
        "    n_fade_out_samples = sample_rate * 60 // tempo # fade out last note\n",
        "    fade_out = np.linspace(1., 0., n_fade_out_samples)**2\n",
        "    merged[-n_fade_out_samples:] *= fade_out\n",
        "    return merged\n",
        "\n",
        "def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):\n",
        "    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n",
        "    if filepath:\n",
        "        from scipy.io import wavfile\n",
        "        samples = (2**15 * samples).astype(np.int16)\n",
        "        wavfile.write(filepath, sample_rate, samples)\n",
        "        return display(Audio(filepath))\n",
        "    else:\n",
        "        return display(Audio(samples, rate=sample_rate))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP1bEWLZFvmY"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "my_chords = tfds.as_numpy(\n",
        "    train.take(1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05vlpoLaOTv9"
      },
      "source": [
        "my_chords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ1Kh9rVOVMR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def f(l):\n",
        "    if isinstance(l,(list,pd.core.series.Series,np.ndarray)):\n",
        "        print(5)\n",
        "    else:\n",
        "        raise Exception('wrong type')\n",
        "\n",
        "\n",
        "chords = np.array([[0,0,0,0]])\n",
        "for ex in my_chords:\n",
        "  chords = np.append(chords, ex, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_A1kBVfOaJE"
      },
      "source": [
        "chords[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ76UgNbQYv4"
      },
      "source": [
        "for i in range(chords.shape[0]):\n",
        "  play_chords(chords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsm-LL-6TMbg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}